{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import pprint\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "from dataset import *\n",
    "from runner import ExptRunner\n",
    "from runner import ExptEvaluator\n",
    "from networks.imageencoder import *\n",
    "from networks.imagedecoder import *\n",
    "from networks.DenseAutoEncoder import DenseAutoEncoder\n",
    "from networks.composedautoencoder import ComposedAutoEncoder\n",
    "from networks.ConvVae import ConvVae\n",
    "from networks.vae import VAE\n",
    "from networks.dense import *\n",
    "from networks.lossfunctions import *\n",
    "from networks.multinet import *\n",
    "from networks.special import *\n",
    "from helpers import *\n",
    "import utils\n",
    "import simplereacherdimensions\n",
    "import simplereacheradapters\n",
    "# from env.simulator import simulator, evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=torch.serialization.SourceChangeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = np.get_printoptions()\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print (torch.cuda.current_device())\n",
    "    torch.cuda.set_device(device)\n",
    "    print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = 'data/simple_reacher/training'\n",
    "# number_of_trajectories = 10\n",
    "number_of_trajectories = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 5.406263113021851 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_data = SimpleReacherOnDemandDataset(root_folder, range(4750), device=device)\n",
    "test_data = SimpleReacherOnDemandDataset(root_folder, range(4750, 5000), device=device)\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103274\n",
      "5399\n",
      "cuda:2\n",
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "print (len(train_data))\n",
    "print (len(test_data))\n",
    "print (train_data.trajectory_data.device)\n",
    "print (test_data.trajectory_data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_expts(train_epochs):\n",
    "    for i in range(len(expts)):\n",
    "        arg_lists = expts[i]\n",
    "        cons_args = arg_lists[0]\n",
    "        train_args = {}\n",
    "        if (len(arg_lists)) > 1:\n",
    "            train_args = arg_lists[1]\n",
    "        test_args = {}\n",
    "        if (len(arg_lists)) > 2:\n",
    "            test_args = arg_lists[2]\n",
    "        \n",
    "        runner = ExptRunner(train_data=train_data, test_data=test_data, device=device, **cons_args)\n",
    "        print (\"Experiment logs folder: {}\".format(runner.log_folder))\n",
    "        with open(runner.log_folder + '/expt.txt', 'w') as f:\n",
    "            f.write(pprint.pformat(arg_lists))\n",
    "        runner.train(train_epochs, **train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First number represents the number of layers, second : channels per each layer, third : kernel size\n",
    "img_auto_encoder = lambda: ComposedAutoEncoder(x_dim=simplereacherdimensions.x_dim,\n",
    "                                               img_res=simplereacherdimensions.img_res,\n",
    "                                               layers_channels=[16, 16, 16, 16],\n",
    "                                               useMaxPool=True,\n",
    "                                               device=device)\n",
    "\n",
    "img_auto_encoder_5_16_7 = lambda: ComposedAutoEncoder(x_dim=simplereacherdimensions.x_dim,\n",
    "                                               img_res=simplereacherdimensions.img_res,\n",
    "                                               layers_channels=[16, 16, 16, 16, 16],\n",
    "                                               useMaxPool=True,\n",
    "                                               device=device,\n",
    "                                               kernel_size=7)\n",
    "\n",
    "img_auto_encoder_5_32_7 = lambda: ComposedAutoEncoder(x_dim=simplereacherdimensions.x_dim,\n",
    "                                               img_res=simplereacherdimensions.img_res,\n",
    "                                               layers_channels=[32, 32, 32, 32, 32],\n",
    "                                               useMaxPool=True,\n",
    "                                               device=device,\n",
    "                                               kernel_size=7)\n",
    "img_auto_encoder_5_16_5 = lambda: ComposedAutoEncoder(x_dim=simplereacherdimensions.x_dim,\n",
    "                                               img_res=simplereacherdimensions.img_res,\n",
    "                                               layers_channels=[16, 16, 16, 16, 16],\n",
    "                                               useMaxPool=True,\n",
    "                                               device=device,\n",
    "                                               kernel_size=5)\n",
    "\n",
    "img_auto_encoder_5_32_5 = lambda: ComposedAutoEncoder(x_dim=simplereacherdimensions.x_dim,\n",
    "                                               img_res=simplereacherdimensions.img_res,\n",
    "                                               layers_channels=[32, 32, 32, 32, 32],\n",
    "                                               useMaxPool=True,\n",
    "                                               device=device,\n",
    "                                               kernel_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "expts = [\n",
    "    [{\n",
    "        \"expt_prefix\":'ImageAutoEncoder-Reacher-ComposedAutoEncoder4-MSE',\n",
    "        \"net_func\": img_auto_encoder,\n",
    "        \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "        \"loss_adapter_func\": mse_loss_adapter,\n",
    "     },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "        \"loss_adapter\": l1_loss_adapter\n",
    "    }],\n",
    "    [{\n",
    "        \"expt_prefix\":'ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_16_7-L1',\n",
    "        \"net_func\": img_auto_encoder_5_16_7,\n",
    "        \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "        \"loss_adapter_func\": l1_loss_adapter,\n",
    "     },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "        \"loss_adapter\": l1_loss_adapter\n",
    "    }],\n",
    "    [{\n",
    "        \"expt_prefix\":'ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_32_7-L1',\n",
    "        \"net_func\": img_auto_encoder_5_32_7,\n",
    "        \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "        \"loss_adapter_func\": l1_loss_adapter,\n",
    "     },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "        \"loss_adapter\": l1_loss_adapter\n",
    "    }],\n",
    "    [{\n",
    "        \"expt_prefix\":'ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_16_5-L1',\n",
    "        \"net_func\": img_auto_encoder_5_16_5,\n",
    "        \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "        \"loss_adapter_func\": l1_loss_adapter,\n",
    "     },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "        \"loss_adapter\": l1_loss_adapter\n",
    "    }],\n",
    "    [{\n",
    "        \"expt_prefix\":'ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_32_5-L1',\n",
    "        \"net_func\": img_auto_encoder_5_32_5,\n",
    "        \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "        \"loss_adapter_func\": l1_loss_adapter,\n",
    "     },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "        \"loss_adapter\": l1_loss_adapter\n",
    "    }],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment logs folder: runs/08-10-20-54-33-ImageAutoEncoder-Reacher-ComposedAutoEncoder4-MSE\n",
      "Experiment logs folder: runs/08-10-21-23-45-ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_16_7-L1\n",
      "Experiment logs folder: runs/08-10-22-03-54-ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_32_7-L1\n",
      "Experiment logs folder: runs/08-10-23-00-44-ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_16_5-L1\n",
      "Experiment logs folder: runs/08-10-23-31-30-ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_32_5-L1\n"
     ]
    }
   ],
   "source": [
    "train_epochs = 10\n",
    "run_expts(train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(\n",
       "  (net): Sequential(\n",
       "    (pol_fc0): Linear(in_features=6, out_features=32, bias=True)\n",
       "    (pol_relu0): ReLU()\n",
       "    (pol_fc1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (pol_relu1): ReLU()\n",
       "    (pol_fc2): Linear(in_features=32, out_features=3, bias=True)\n",
       "    (pol_sig2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testchkpt = torch.load('runs/07-29-04-24-51-PolicyNoScalingOfInputsAndOutputs-Reacher-Dense-MSE/train_checkpoint.tar', map_location=device)\n",
    "testNet = testchkpt['model']\n",
    "testNet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_file = 'runs/07-19/07-20-00-08-11-ImageAutoEncoder-Reacher-ComposedAutoEncoder-L1/train_checkpoint.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chkpt_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-08bf9dcf3f5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExptEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchkpt_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'chkpt_file' is not defined"
     ]
    }
   ],
   "source": [
    "e = ExptEvaluator(chkpt_file, train_data, test_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "e.net = e.net.to(device)\n",
    "print (e.net.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with checkpoint file runs/08-10/08-10-20-54-33-ImageAutoEncoder-Reacher-ComposedAutoEncoder4-MSE/train_checkpoint.tar\n",
      "Done with checkpoint file runs/08-10/08-10-21-23-45-ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_16_7-L1/train_checkpoint.tar\n",
      "Done with checkpoint file runs/08-10/08-10-22-03-54-ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_32_7-L1/train_checkpoint.tar\n",
      "Done with checkpoint file runs/08-10/08-10-23-00-44-ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_16_5-L1/train_checkpoint.tar\n",
      "Done with checkpoint file runs/08-10/08-10-23-31-30-ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_32_5-L1/train_checkpoint.tar\n",
      "Time Taken: 728.2372713088989 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for chkpt_file in utils.enumerate_files(rootdir='runs/08-10'):\n",
    "    e = ExptEvaluator(chkpt_file, train_data, test_data, device)\n",
    "    e.test()\n",
    "    print ('Done with checkpoint file {}'.format(chkpt_file))\n",
    "\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample(ip_batch, op_batch, filePath):\n",
    "    cmap = plt.get_cmap('gray')\n",
    "    ip_batch = ip_batch.cpu()\n",
    "    op_batch = op_batch.cpu()\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    plt.imshow(ip_batch.reshape(256, 256), cmap=cmap, vmin=0, vmax=1)\n",
    "    ax.title.set_text('Original')\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    plt.imshow(op_batch.reshape(256, 256), cmap=cmap, vmin=0, vmax=1)\n",
    "    ax.title.set_text('Recontructed')\n",
    "    fig.savefig(filePath)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 7.420027256011963 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for chkpt_file in utils.enumerate_files(rootdir='runs/08-10'):\n",
    "    chkpt = torch.load(chkpt_file, map_location=device)\n",
    "    net = chkpt['model']\n",
    "    data_adapter_func = chkpt['input_adapter']\n",
    "    # data_to_label_adapter = chkpt['label_adapter']\n",
    "    log_folder = os.path.dirname(chkpt_file)\n",
    "    for dataset, setName in zip([train_data, test_data], ['training_set', 'test_set']):\n",
    "        for crit in ['good', 'bad']:\n",
    "            with open(os.path.join(log_folder, '{}_{}_samples.txt'.format(setName, crit)), 'r') as f:\n",
    "                while True:\n",
    "                    line = f.readline()\n",
    "                    if len(line) == 0:\n",
    "                        break\n",
    "                    idx = int(line)\n",
    "                    ip_batch = data_adapter_func(dataset[idx])\n",
    "                    with torch.no_grad():\n",
    "                        op_batch = net(ip_batch)\n",
    "                        save_sample(ip_batch, op_batch, os.path.join(log_folder, '{}_{}_{}.png'.format(setName, crit, idx)))\n",
    "\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdapterNet(nn.Module):\n",
    "    def __init__(self, testNet, ip_adapter=None, op_adapter=None):\n",
    "        super().__init__()\n",
    "        self.testNet = testNet\n",
    "        self.ip_adapter = ip_adapter if ip_adapter else lambda x:x\n",
    "        self.op_adapter = op_adapter if op_adapter else lambda x:x\n",
    "        \n",
    "    def forward(self, data):\n",
    "        ip = self.ip_adapter(data)\n",
    "        op = self.testNet(ip)\n",
    "        return self.op_adapter(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "t475 = test_data.trajectory_data[test_data.trajectory_index[:, 0] == 475, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 9])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t475.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_adapter = lambda x:x.float()\n",
    "op_adapter = lambda x:((x * (2 * simplereacherdimensions.joint_max)) - (simplereacherdimensions.joint_max))\n",
    "ev = evaluator(AdapterNet(testNet, ip_adapter=ip_adapter, op_adapter=op_adapter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating env\n"
     ]
    }
   ],
   "source": [
    "t475_output = ev.rollout(t475)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0023, 0.4158, 1.8592, 0.9967, 1.1594, 2.5409],\n",
       "        [1.9043, 0.5139, 1.7611, 0.9996, 1.1593, 2.5384],\n",
       "        [1.8053, 0.5956, 1.6621, 1.0007, 1.1592, 2.5375],\n",
       "        [1.7063, 0.5854, 1.7592, 1.0011, 1.1592, 2.5371],\n",
       "        [1.6073, 0.6034, 1.8582, 1.0012, 1.1592, 2.5370],\n",
       "        [1.5083, 0.6397, 1.9572, 1.0013, 1.1592, 2.5369],\n",
       "        [1.4093, 0.7053, 2.0562, 1.0013, 1.1592, 2.5369],\n",
       "        [1.3102, 0.7835, 2.1552, 1.0013, 1.1592, 2.5369],\n",
       "        [1.2112, 0.8817, 2.2542, 1.0013, 1.1592, 2.5369],\n",
       "        [1.1122, 0.9807, 2.2044, 1.0013, 1.1592, 2.5369],\n",
       "        [1.0132, 1.0797, 2.2021, 1.0013, 1.1592, 2.5369],\n",
       "        [0.9142, 1.1061, 2.3001, 1.0013, 1.1592, 2.5369],\n",
       "        [0.8152, 1.0081, 2.3929, 1.0013, 1.1592, 2.5369],\n",
       "        [0.7162, 0.9091, 2.3035, 1.0013, 1.1592, 2.5369],\n",
       "        [0.6172, 0.8319, 2.2383, 1.0013, 1.1592, 2.5369],\n",
       "        [0.5182, 0.7456, 2.1949, 1.0013, 1.1592, 2.5369],\n",
       "        [0.4192, 0.6712, 2.1471, 1.0013, 1.1592, 2.5369],\n",
       "        [0.3202, 0.6230, 2.0908, 1.0013, 1.1592, 2.5369],\n",
       "        [0.2212, 0.5687, 2.0249, 1.0013, 1.1592, 2.5369]], dtype=torch.float64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t475_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0023, 0.4158, 1.8592, 0.9967, 1.1594, 2.5409],\n",
       "        [1.9702, 0.3573, 1.9128, 0.9967, 1.1594, 2.5409],\n",
       "        [1.9658, 0.3536, 1.9160, 0.9967, 1.1594, 2.5409],\n",
       "        [1.9073, 0.4041, 1.9532, 0.9967, 1.1594, 2.5409],\n",
       "        [1.8453, 0.4557, 1.9929, 0.9967, 1.1594, 2.5409],\n",
       "        [1.7844, 0.5060, 2.0321, 0.9967, 1.1594, 2.5409],\n",
       "        [1.7239, 0.5562, 2.0713, 0.9967, 1.1594, 2.5409],\n",
       "        [1.6633, 0.6065, 2.1104, 0.9967, 1.1594, 2.5409],\n",
       "        [1.6027, 0.6567, 2.1495, 0.9967, 1.1594, 2.5409],\n",
       "        [1.5421, 0.7070, 2.1887, 0.9967, 1.1594, 2.5409],\n",
       "        [1.4815, 0.7573, 2.2278, 0.9967, 1.1594, 2.5409],\n",
       "        [1.4209, 0.8075, 2.2670, 0.9967, 1.1594, 2.5409],\n",
       "        [1.3603, 0.8578, 2.3061, 0.9967, 1.1594, 2.5409],\n",
       "        [1.2997, 0.9080, 2.3452, 0.9967, 1.1594, 2.5409],\n",
       "        [1.2391, 0.9583, 2.3844, 0.9967, 1.1594, 2.5409],\n",
       "        [1.1785, 1.0086, 2.4235, 0.9967, 1.1594, 2.5409],\n",
       "        [1.1179, 1.0588, 2.4627, 0.9967, 1.1594, 2.5409],\n",
       "        [1.0573, 1.1091, 2.5018, 0.9967, 1.1594, 2.5409],\n",
       "        [0.9967, 1.1594, 2.5409, 0.9967, 1.1594, 2.5409]], dtype=torch.float64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t475[:, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't475' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4e74eef4569d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt475\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt475_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt475\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt475_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't475' is not defined"
     ]
    }
   ],
   "source": [
    "print (F.l1_loss(t475[:, :3], t475_output[:, :3]))\n",
    "print (F.l1_loss(t475[-1:, :3], t475_output[-1:, :3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = np.random.randint(len(train_data), size=5)\n",
    "test_samples = np.random.randint(len(test_data), size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nThe NVIDIA driver on your system is too old (found version 10010).\nPlease update your GPU driver by downloading and installing a new\nversion from the URL: http://www.nvidia.com/Download/index.aspx\nAlternatively, go to: https://pytorch.org to install\na PyTorch version that has been compiled with your version\nof the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-17f440fb0020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mip_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimplereacheradapters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIt_scaled_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mop_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mip_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mop_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/DemoPlanner-IEdHlcpb/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GH/PradeepKadubandi/DemoPlanner/networks/composedautoencoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data_batch)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mip_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_res\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mip_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/DemoPlanner-IEdHlcpb/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n\u001b[1;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise AssertionError(\n",
      "\u001b[0;32m~/.local/share/virtualenvs/DemoPlanner-IEdHlcpb/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mAlternatively\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgo\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m \u001b[0mto\u001b[0m \u001b[0minstall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0ma\u001b[0m \u001b[0mPyTorch\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mbeen\u001b[0m \u001b[0mcompiled\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0myour\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m of the CUDA driver.\"\"\".format(str(torch._C._cuda_getDriverVersion())))\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nThe NVIDIA driver on your system is too old (found version 10010).\nPlease update your GPU driver by downloading and installing a new\nversion from the URL: http://www.nvidia.com/Download/index.aspx\nAlternatively, go to: https://pytorch.org to install\na PyTorch version that has been compiled with your version\nof the CUDA driver."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "cmap = plt.get_cmap('gray')\n",
    "\n",
    "for chkpt_file in utils.enumerate_files(rootdir='runs/07-19'):\n",
    "    log_folder = os.path.dirname(chkpt_file)\n",
    "    chkpt = torch.load(chkpt_file, map_location=device)\n",
    "    testNet = chkpt['model']\n",
    "    testNet.eval()\n",
    "    for idx in test_samples:\n",
    "        fileName = 'TestSample_{}'.format(str(idx))\n",
    "        fig = plt.figure()\n",
    "        ip_batch = simplereacheradapters.It_scaled_adapter(test_data[idx.item()])\n",
    "        with torch.no_grad():\n",
    "            op_batch = testNet(ip_batch)\n",
    "        ip_batch = ip_batch.cpu()\n",
    "        op_batch = op_batch.cpu()\n",
    "        plt.figure()\n",
    "        ax = plt.subplot(1, 2, 1)\n",
    "        plt.imshow(ip_batch.reshape(256, 256), cmap=cmap)\n",
    "        ax.title.set_text('Original')\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax = plt.subplot(1, 2, 2)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        plt.imshow(op_batch.reshape(256, 256), cmap=cmap)\n",
    "        ax.title.set_text('Recontructed')\n",
    "        plt.show()\n",
    "        #fig.savefig(log_folder + '/' + filename + '.png')\n",
    "\n",
    "\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
