{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import pprint\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "from dataset import *\n",
    "from runner import ExptRunner\n",
    "from runner import ExptEvaluator\n",
    "from networks.imageencoder import *\n",
    "from networks.imagedecoder import *\n",
    "from networks.DenseAutoEncoder import DenseAutoEncoder\n",
    "from networks.composedautoencoder import ComposedAutoEncoder\n",
    "from networks.ConvVae import ConvVae\n",
    "from networks.vae import VAE\n",
    "from networks.dense import *\n",
    "from networks.lossfunctions import *\n",
    "from networks.reacherspecial import *\n",
    "from helpers import *\n",
    "import utils\n",
    "import plottinghelpers\n",
    "import simplereacherdimensions\n",
    "import simplereacheradapters\n",
    "from env.simulator import simulator, evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=torch.serialization.SourceChangeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = np.get_printoptions()\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     print (torch.cuda.current_device())\n",
    "#     torch.cuda.set_device(device)\n",
    "#     print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = 'data/simple_reacher/training'\n",
    "# number_of_trajectories = 10\n",
    "number_of_trajectories = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 4.953538179397583 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_data = SimpleReacherOnDemandDataset(root_folder, range(4750), device=device)\n",
    "test_data = SimpleReacherOnDemandDataset(root_folder, range(4750, 5000), device=device)\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103274\n",
      "5399\n",
      "cuda:2\n",
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "print (len(train_data))\n",
    "print (len(test_data))\n",
    "print (train_data.trajectory_data.device)\n",
    "print (test_data.trajectory_data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_expts(train_epochs):\n",
    "    for i in range(len(expts)):\n",
    "        arg_lists = expts[i]\n",
    "        cons_args = arg_lists[0]\n",
    "        train_args = {}\n",
    "        if (len(arg_lists)) > 1:\n",
    "            train_args = arg_lists[1]\n",
    "        test_args = {}\n",
    "        if (len(arg_lists)) > 2:\n",
    "            test_args = arg_lists[2]\n",
    "        \n",
    "        runner = ExptRunner(train_data=train_data, test_data=test_data, device=device, **cons_args)\n",
    "        print (\"Experiment logs folder: {}\".format(runner.log_folder))\n",
    "        with open(runner.log_folder + '/expt.txt', 'w') as f:\n",
    "            f.write(pprint.pformat(arg_lists))\n",
    "        runner.train(train_epochs, **train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First number represents the number of layers, second : channels per each layer, third : kernel size\n",
    "img_auto_encoder_4_16_3 = lambda: ComposedAutoEncoder(x_dim=simplereacherdimensions.x_dim,\n",
    "                                               img_res=simplereacherdimensions.img_res,\n",
    "                                               layers_channels=[16, 16, 16, 16],\n",
    "                                               useMaxPool=True,\n",
    "                                               device=device)\n",
    "\n",
    "img_auto_encoder_5_16_7 = lambda: ComposedAutoEncoder(x_dim=simplereacherdimensions.x_dim,\n",
    "                                               img_res=simplereacherdimensions.img_res,\n",
    "                                               layers_channels=[16, 16, 16, 16, 16],\n",
    "                                               useMaxPool=True,\n",
    "                                               device=device,\n",
    "                                               kernel_size=7)\n",
    "\n",
    "img_auto_encoder_5_32_7 = lambda: ComposedAutoEncoder(x_dim=simplereacherdimensions.x_dim,\n",
    "                                               img_res=simplereacherdimensions.img_res,\n",
    "                                               layers_channels=[32, 32, 32, 32, 32],\n",
    "                                               useMaxPool=True,\n",
    "                                               device=device,\n",
    "                                               kernel_size=7)\n",
    "img_auto_encoder_5_16_5 = lambda: ComposedAutoEncoder(x_dim=simplereacherdimensions.x_dim,\n",
    "                                               img_res=simplereacherdimensions.img_res,\n",
    "                                               layers_channels=[16, 16, 16, 16, 16],\n",
    "                                               useMaxPool=True,\n",
    "                                               device=device,\n",
    "                                               kernel_size=5)\n",
    "\n",
    "img_auto_encoder_5_32_5 = lambda: ComposedAutoEncoder(x_dim=simplereacherdimensions.x_dim,\n",
    "                                               img_res=simplereacherdimensions.img_res,\n",
    "                                               layers_channels=[32, 32, 32, 32, 32],\n",
    "                                               useMaxPool=True,\n",
    "                                               device=device,\n",
    "                                               kernel_size=5)\n",
    "img_encoder_4_16_3 = lambda: ImageEncoderFlatInput(img_res=simplereacherdimensions.img_res,\n",
    "                                               input_channels=1,\n",
    "                                               layers_channels=[16, 16, 16, 16],\n",
    "                                               prefix='enc',\n",
    "                                               useMaxPool=True,\n",
    "                                               addFlatten=True,\n",
    "                                               kernel_size=3)\n",
    "img_encoder_5_32_5 = lambda: ImageEncoderFlatInput(img_res=simplereacherdimensions.img_res,\n",
    "                                               input_channels=1,\n",
    "                                               layers_channels=[32, 32, 32, 32, 32],\n",
    "                                               prefix='enc',\n",
    "                                               useMaxPool=True,\n",
    "                                               addFlatten=True,\n",
    "                                               kernel_size=5)\n",
    "img_encoder_5_32_7 = lambda: ImageEncoderFlatInput(img_res=simplereacherdimensions.img_res,\n",
    "                                               input_channels=1,\n",
    "                                               layers_channels=[32, 32, 32, 32, 32],\n",
    "                                               prefix='enc',\n",
    "                                               useMaxPool=True,\n",
    "                                               addFlatten=True,\n",
    "                                               kernel_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained(folder):\n",
    "    chkptFile = os.path.join('runs', folder, 'train_checkpoint.tar')\n",
    "    return torch.load(chkptFile, map_location=device)['model']\n",
    "\n",
    "def finetune_pretrained_end_to_end(net):\n",
    "    c = copy.deepcopy(net)\n",
    "    configure_net_training(c, True)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_image_auto_enc = load_pretrained('AutoEncoders/09-03/09-03-11-00-53-ImageAutoEncoder-Reacher-ComposedAutoEncoder4-L1')\n",
    "pretrain_policy = load_pretrained('Policies/08-19/08-19-13-32-36-Policy-Reacher-Dense4WithTanh-L1')\n",
    "pretrain_img_to_env = load_pretrained('AutoEncoders/08-12/run1-img-to-env/08-12-18-44-36-ImageToEnv-Reacher-Conv4Dense3-MSE/')\n",
    "pretrain_pol_augmented = load_pretrained('Policies/08-24/08-24-20-45-40-Policy_Augmented-Reacher-Dense4WithTanh-L1')\n",
    "pretrain_pol_trig = load_pretrained('Policies/08-25/run1-ld-policy/08-25-10-34-36-Policy_TrigAugmented-Reacher-Dense4WithTanh-L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_layers = [16,16,16,16]\n",
    "z_dim = 4096 # 16 * 26 * 16 , This should be set based on above img_layers\n",
    "# z_dim = 2048\n",
    "env_layers = [6, 512, z_dim]\n",
    "in_channels = 1\n",
    "img_encoder = lambda: ImageEncoderFlatInput(in_channels, img_layers, 'imgenc', useMaxPool=True, addFlatten=True, img_res=simplereacheradapters.img_res)\n",
    "# img_decoder = lambda: ImageDecoderFlatInput(z_dim, list(reversed(img_layers)), in_channels, 'imgdec', useSigmoid=True)\n",
    "# env_encoder = lambda: Dense(env_layers, use_last_act=False, prefix='envenc')\n",
    "env_decoder = lambda: Dense(list(reversed(env_layers)), last_act='sigmoid', prefix='envdec')\n",
    "combined = lambda l1, l2: nn.Sequential(OrderedDict([\n",
    "                              ('EncNet', l1()),\n",
    "                              ('DecNet', l2()),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_enc_pretrained_img_dec():\n",
    "    net = combined(env_encoder, img_decoder).to(device)\n",
    "    load_mapped_state_dict(net, pretrain_imgEncDec, 'DecNet.net.imgdec', 'decoder.net.dec')\n",
    "    return net\n",
    "\n",
    "def pretrained_img_enc_env_dec(i_encoder, e_decoder):\n",
    "    net = combined(i_encoder, e_decoder).to(device)\n",
    "    load_mapped_state_dict(net, pretrain_image_auto_enc, 'EncNet.net.imgenc', 'encoder.net.enc')\n",
    "    return net\n",
    "\n",
    "def img_enc_env_dec_from_pretrained():\n",
    "    net = combined(img_encoder, env_decoder).to(device)\n",
    "    load_mapped_state_dict(net, pretrain_imgEncDec, 'EncNet.net.imgenc', 'encoder.net.enc')\n",
    "    load_mapped_state_dict(net, pretrain_envEncDec, 'DecNet.net.envdec_fc0', 'decoder.dec_fc1') # Hacky\n",
    "    return net\n",
    "\n",
    "def latent_policy_from_latent(latentReference, policy=None, fix_indices=[0]):\n",
    "    latent = copy.deepcopy(latentReference)\n",
    "    if not policy:\n",
    "        policy = Dense(layer_dims=[6, 16, 16, 3], last_act='tanh', prefix='pol')\n",
    "    configure_net_training(latent, False)\n",
    "    net = LatentPolicyNet(latent=latent, policy=policy).to(device)\n",
    "    return net\n",
    "\n",
    "def latent_policy_fixed_img_enc_pol_train_env_dec(policy=pretrain_policy, e_decoder=env_decoder, i_encoder=img_encoder):\n",
    "    latent = pretrained_img_enc_env_dec(i_encoder, e_decoder)\n",
    "    policy = copy.deepcopy(policy)\n",
    "    configure_net_training(policy, False)\n",
    "    configure_net_training(latent[0], False)\n",
    "    return LatentPolicyNet(latent=latent, policy=policy).to(device)\n",
    "\n",
    "def latent_policy_pretrained_img_enc_pol_train_end_to_end(policy=pretrain_policy, e_decoder=env_decoder, i_encoder=img_encoder):\n",
    "    latent = pretrained_img_enc_env_dec(i_encoder, e_decoder)\n",
    "    policy = copy.deepcopy(policy)\n",
    "    return LatentPolicyNet(latent=latent, policy=policy).to(device)\n",
    "\n",
    "def latentFilter_gt_x_latent_y(data, latent_output):\n",
    "    return torch.cat((Xt_scaled_adapter(data), latent_output[:, 2:]), dim=1)\n",
    "\n",
    "def image_to_env(conv, dense):\n",
    "    return combined(conv, dense)\n",
    "\n",
    "def LPGTX_fixed_img_enc_pol_train_env_dec(policy=pretrain_policy, e_decoder=env_decoder, i_encoder=img_encoder):\n",
    "    latent = pretrained_img_enc_env_dec(i_encoder, e_decoder)\n",
    "    policy = copy.deepcopy(policy)\n",
    "    configure_net_training(policy, False)\n",
    "    configure_net_training(latent[0], False)\n",
    "    return LatentPolicyWithGroundTruthXNet(latent=latent, policy=policy).to(device)\n",
    "\n",
    "def LPGTX_fixed_img_enc_pol_train_env_dec_end_to_end(policy=pretrain_policy, e_decoder=env_decoder, i_encoder=img_encoder):\n",
    "    latent = pretrained_img_enc_env_dec(i_encoder, e_decoder)\n",
    "    policy = copy.deepcopy(policy)\n",
    "    return LatentPolicyWithGroundTruthXNet(latent=latent, policy=policy).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_func = lambda: LPGTX_fixed_img_enc_pol_train_env_dec(\n",
    "    i_encoder=img_encoder_4_16_3,\n",
    "    e_decoder=lambda: Dense([4096, 512, 3], last_act='sigmoid', prefix='envdec'),\n",
    "    policy=pretrain_policy\n",
    ")\n",
    "net = net_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip1 = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentPolicyWithGroundTruthXNet(\n",
       "  (latent): Sequential(\n",
       "    (EncNet): ImageEncoderFlatInput(\n",
       "      (net): Sequential(\n",
       "        (enc_conv0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (enc_relu0): ReLU()\n",
       "        (enc_maxpool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (enc_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (enc_relu1): ReLU()\n",
       "        (enc_maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (enc_conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (enc_relu2): ReLU()\n",
       "        (enc_maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (enc_conv3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (enc_relu3): ReLU()\n",
       "        (enc_maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (enc_flat): Flatten()\n",
       "      )\n",
       "      (reshapeInput): Reshape()\n",
       "    )\n",
       "    (DecNet): Dense(\n",
       "      (net): Sequential(\n",
       "        (envdec_fc0): Linear(in_features=4096, out_features=512, bias=True)\n",
       "        (envdec_relu0): ReLU()\n",
       "        (envdec_fc1): Linear(in_features=512, out_features=3, bias=True)\n",
       "        (envdec_sig1): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (policy): Dense(\n",
       "    (net): Sequential(\n",
       "      (pol_fc0): Linear(in_features=6, out_features=16, bias=True)\n",
       "      (pol_relu0): ReLU()\n",
       "      (pol_fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (pol_relu1): ReLU()\n",
       "      (pol_fc2): Linear(in_features=16, out_features=3, bias=True)\n",
       "      (pol_tanh2): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144:False\n",
      "16:False\n",
      "2304:False\n",
      "16:False\n",
      "2304:False\n",
      "16:False\n",
      "2304:False\n",
      "16:False\n",
      "2097152:True\n",
      "512:True\n",
      "1536:True\n",
      "3:True\n",
      "96:False\n",
      "16:False\n",
      "256:False\n",
      "16:False\n",
      "48:False\n",
      "3:False\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    print ('{}:{}'.format(p.numel(), p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "expts = [\n",
    "#   Image to Policy: Use pretrained image encoder, policy, train decoder/end-to-end \n",
    "#     [{\n",
    "#         \"expt_prefix\":'Finetune_LowLR_FixImageEncoderTrigPolicy_TrainDecoder-Reacher-Conv5Dense4-L1',\n",
    "#         \"net_func\": lambda: finetune_pretrained('Policies/08-19/08-19-20-24-49-FixImageEncoderPolicy_TrainDecoder-Reacher-Conv5Dense4-L1'),\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#         \"optimizer_func\": lambda net: optim.Adam(net.parameters(), lr=1e-4)\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'LPGTX_FixImageEncoderPolicy_TrainDecoderToY-Reacher-Conv4Dense3-L1',\n",
    "#         \"net_func\": lambda: LPGTX_fixed_img_enc_pol_train_env_dec(\n",
    "#             i_encoder=img_encoder_4_16_3,\n",
    "#             e_decoder=lambda: Dense([4096, 512, 3], last_act='sigmoid', prefix='envdec'),\n",
    "#             policy=pretrain_policy\n",
    "#         ),\n",
    "#         \"data_adapter_func\": simplereacheradapters.XtIt_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'LPGTX_FixImageEncoderPolicy_TrainDecoderToY-Reacher-Conv4Dense3-L1',\n",
    "#         \"net_func\": lambda: LPGTX_fixed_img_enc_pol_train_env_dec(\n",
    "#             i_encoder=img_encoder_4_16_3,\n",
    "#             e_decoder=lambda: Dense([4096, 512, 6], last_act='sigmoid', prefix='envdec'),\n",
    "#             policy=pretrain_pol_augmented\n",
    "#         ),\n",
    "#         \"data_adapter_func\": simplereacheradapters.XtIt_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#     }],\n",
    "    [{\n",
    "        \"expt_prefix\":'LPGTX_PretrainedImageEncoderPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1',\n",
    "        \"net_func\": lambda: LPGTX_fixed_img_enc_pol_train_env_dec_end_to_end(\n",
    "            i_encoder=img_encoder_4_16_3,\n",
    "            e_decoder=lambda: Dense([4096, 512, 3], last_act='sigmoid', prefix='envdec'),\n",
    "            policy=pretrain_policy\n",
    "        ),\n",
    "        \"data_adapter_func\": simplereacheradapters.XtIt_scaled_adapter,\n",
    "        \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "        \"loss_adapter_func\": l1_loss_adapter,\n",
    "     },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "    }],\n",
    "    [{\n",
    "        \"expt_prefix\":'LPGTX_PretrainedImageEncoderAugmentedPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1',\n",
    "        \"net_func\": lambda: LPGTX_fixed_img_enc_pol_train_env_dec_end_to_end(\n",
    "            i_encoder=img_encoder_4_16_3,\n",
    "            e_decoder=lambda: Dense([4096, 512, 6], last_act='sigmoid', prefix='envdec'),\n",
    "            policy=pretrain_pol_augmented\n",
    "        ),\n",
    "        \"data_adapter_func\": simplereacheradapters.XtIt_scaled_adapter,\n",
    "        \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "        \"loss_adapter_func\": l1_loss_adapter,\n",
    "     },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "    }],\n",
    "    [{\n",
    "        \"expt_prefix\":'LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1',\n",
    "        \"net_func\": lambda: finetune_pretrained_end_to_end(\n",
    "            load_pretrained('Policies/09-09/run2_100_epochs/09-09-21-22-50-LPGTX_FixImageEncoderPolicy_TrainDecoderToY-Reacher-Conv4Dense3-L1')\n",
    "        ),\n",
    "        \"data_adapter_func\": simplereacheradapters.XtIt_scaled_adapter,\n",
    "        \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "        \"loss_adapter_func\": l1_loss_adapter,\n",
    "     },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "        \"optimizer_func\": lambda net: optim.Adam(net.parameters(), lr=1e-4)\n",
    "    }],\n",
    "    [{\n",
    "        \"expt_prefix\":'LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1',\n",
    "        \"net_func\": lambda: finetune_pretrained_end_to_end(\n",
    "            load_pretrained('Policies/09-09/run2_100_epochs/09-10-01-03-19-LPGTX_FixImageEncoderAugmentedPolicy_TrainDecoderToY-Reacher-Conv4Dense3-L1')\n",
    "        ),\n",
    "        \"data_adapter_func\": simplereacheradapters.XtIt_scaled_adapter,\n",
    "        \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "        \"loss_adapter_func\": l1_loss_adapter,\n",
    "     },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "        \"optimizer_func\": lambda net: optim.Adam(net.parameters(), lr=1e-4)\n",
    "    }],\n",
    "    [{\n",
    "        \"expt_prefix\":'LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1',\n",
    "        \"net_func\": lambda: finetune_pretrained_end_to_end(\n",
    "            load_pretrained('Policies/09-09/run2_100_epochs/09-09-21-22-50-LPGTX_FixImageEncoderPolicy_TrainDecoderToY-Reacher-Conv4Dense3-L1')\n",
    "        ),\n",
    "        \"data_adapter_func\": simplereacheradapters.XtIt_scaled_adapter,\n",
    "        \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "        \"loss_adapter_func\": l1_loss_adapter,\n",
    "     },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "    }],\n",
    "    [{\n",
    "        \"expt_prefix\":'LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1',\n",
    "        \"net_func\": lambda: finetune_pretrained_end_to_end(\n",
    "            load_pretrained('Policies/09-09/run2_100_epochs/09-10-01-03-19-LPGTX_FixImageEncoderAugmentedPolicy_TrainDecoderToY-Reacher-Conv4Dense3-L1')\n",
    "        ),\n",
    "        \"data_adapter_func\": simplereacheradapters.XtIt_scaled_adapter,\n",
    "        \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "        \"loss_adapter_func\": l1_loss_adapter,\n",
    "     },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "    }],\n",
    "#   Train policy using fixed Image To Env function\n",
    "#     [{\n",
    "#         \"expt_prefix\":'FixImageToEnv_TrainFreshPolicy-Reacher-Conv4Dense3-MSE',\n",
    "#         \"net_func\": lambda: latent_policy_from_latent(pretrain_img_to_env),\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": mse_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#   Image To Env function\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageToEnv-Reacher-Conv4Dense3-MSE',\n",
    "#         \"net_func\": lambda: image_to_env(img_encoder, env_decoder),\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.XtYt_scaled_adapter,\n",
    "#         \"loss_adapter_func\": mse_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#   Policy\n",
    "#     [{\n",
    "#         \"expt_prefix\":'Policy-Reacher-Dense4WithTanh-L1',\n",
    "#         \"net_func\": lambda: Dense(layer_dims=[6, 16, 16, 3], last_act='tanh', prefix='pol'),\n",
    "#         \"data_adapter_func\": simplereacheradapters.XtYt_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#   Image to policy : Direct\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageToPolicy-Reacher-ComposedAutoEncoder5Dense-L1',\n",
    "#         \"net_func\": lambda: combined(img_encoder_5_32_5, lambda: Dense(layer_dims=[2048, 512, 128, 3], last_act='tanh', prefix='pol')), \n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#   Image autoencoder\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageAutoEncoder-Reacher-ComposedAutoEncoder4-L1',\n",
    "#         \"net_func\": img_auto_encoder_4_16_3,\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment logs folder: runs/09-10-10-40-06-LPGTX_PretrainedImageEncoderPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1\n",
      "Experiment logs folder: runs/09-10-11-37-11-LPGTX_PretrainedImageEncoderAugmentedPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1\n",
      "Experiment logs folder: runs/09-10-12-32-12-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1\n",
      "Experiment logs folder: runs/09-10-13-25-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1\n",
      "Experiment logs folder: runs/09-10-14-26-17-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1\n",
      "Experiment logs folder: runs/09-10-15-26-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1\n"
     ]
    }
   ],
   "source": [
    "train_epochs = 20\n",
    "run_expts(train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with checkpoint file runs/Policies/09-10/run1-10-epochs/09-10-10-40-06-LPGTX_PretrainedImageEncoderPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "Done with checkpoint file runs/Policies/09-10/run1-10-epochs/09-10-11-37-11-LPGTX_PretrainedImageEncoderAugmentedPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "Done with checkpoint file runs/Policies/09-10/run1-10-epochs/09-10-12-32-12-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "Done with checkpoint file runs/Policies/09-10/run1-10-epochs/09-10-13-25-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "Done with checkpoint file runs/Policies/09-10/run1-10-epochs/09-10-14-26-17-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "Done with checkpoint file runs/Policies/09-10/run1-10-epochs/09-10-15-26-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "Time Taken: 801.6531670093536 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for chkpt_file in utils.enumerate_files(rootdir='runs/Policies/09-10'):\n",
    "    e = ExptEvaluator(chkpt_file, train_data, test_data, device)\n",
    "    e.test()\n",
    "    print ('Done with checkpoint file {}'.format(chkpt_file))\n",
    "\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder : runs/09-03-11-00-53-ImageAutoEncoder-Reacher-ComposedAutoEncoder4-L1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "plottinghelpers.save_all_plots_img_auto_encoder_run(rootdir='runs/09-03-11-00-53-ImageAutoEncoder-Reacher-ComposedAutoEncoder4-L1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 1.5567817687988281 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "plottinghelpers.generate_img_reconstructions(\n",
    "    rootdir='runs/09-03-11-00-53-ImageAutoEncoder-Reacher-ComposedAutoEncoder4-L1',\n",
    "    device=device, train_data=train_data, test_data=test_data,\n",
    "    img_res=simplereacherdimensions.img_res)\n",
    "\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu = torch.device('cpu')\n",
    "cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 0.00012683868408203125 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_traj_data = SimpleReacherTrajectoryDataset(root_folder, range(500), device=cpu) #only a subset of training_data\n",
    "test_traj_data = SimpleReacherTrajectoryDataset(root_folder, range(4750, 5000), device=cpu)\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_net = nn.Sequential(OrderedDict([\n",
    "                      ('ItoY', pretrain_img_to_env),\n",
    "                      ('pol', pretrain_policy),\n",
    "                    ])).to(cpu)\n",
    "pretrained_net = pretrained_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing checkpoint file runs/Policies/09-10/run1-10-epochs/09-10-10-40-06-LPGTX_PretrainedImageEncoderPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "-------------------------------------------------------------\n",
      "runs/Policies/09-10/run1-10-epochs/09-10-10-40-06-LPGTX_PretrainedImageEncoderPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region (Goal Loss <= 0.009999999776482582): 0.0\n",
      "Average Policy L1 Loss: 0.04789937660098076\n",
      "Average Trajectory Loss: 0.4603148102760315\n",
      "Average Goal Loss: 0.9694252610206604\n",
      "Average Combined State Loss: 0.23226812481880188\n",
      "\n",
      "Least Policy L1 Error: Index = 67, Value = 0.03257681801915169\n",
      "Least Trajectory Error: Index = 67, Value = 0.06618227809667587\n",
      "Least Goal Error: Index = 38, Value = 0.1287856101989746\n",
      "\n",
      "Highest Policy L1 Error: Index = 195, Value = 0.06195828691124916\n",
      "Highest Trajectory Error: Index = 97, Value = 0.9053876399993896\n",
      "Highest Goal Error: Index = 7, Value = 1.8788020610809326\n",
      "-------------------------------------------------------------\n",
      "runs/Policies/09-10/run1-10-epochs/09-10-10-40-06-LPGTX_PretrainedImageEncoderPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region (Goal Loss <= 0.009999999776482582): 0.0\n",
      "Average Policy L1 Loss: 0.048196565359830856\n",
      "Average Trajectory Loss: 0.4630560576915741\n",
      "Average Goal Loss: 0.9748162031173706\n",
      "Average Combined State Loss: 0.23362596333026886\n",
      "\n",
      "Least Policy L1 Error: Index = 67, Value = 0.03257681801915169\n",
      "Least Trajectory Error: Index = 67, Value = 0.06618227809667587\n",
      "Least Goal Error: Index = 38, Value = 0.12878572940826416\n",
      "\n",
      "Highest Policy L1 Error: Index = 195, Value = 0.06195828691124916\n",
      "Highest Trajectory Error: Index = 97, Value = 0.9053876399993896\n",
      "Highest Goal Error: Index = 7, Value = 1.8788020610809326\n",
      "\n",
      "Start processing checkpoint file runs/Policies/09-10/run1-10-epochs/09-10-11-37-11-LPGTX_PretrainedImageEncoderAugmentedPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "-------------------------------------------------------------\n",
      "runs/Policies/09-10/run1-10-epochs/09-10-11-37-11-LPGTX_PretrainedImageEncoderAugmentedPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region (Goal Loss <= 0.009999999776482582): 1.0\n",
      "Average Policy L1 Loss: 0.015251308679580688\n",
      "Average Trajectory Loss: 0.0912482738494873\n",
      "Average Goal Loss: 0.11615020036697388\n",
      "Average Combined State Loss: 0.04770154505968094\n",
      "\n",
      "Least Policy L1 Error: Index = 208, Value = 0.004971636924892664\n",
      "Least Trajectory Error: Index = 127, Value = 0.011816076003015041\n",
      "Least Goal Error: Index = 164, Value = 0.006560737732797861\n",
      "\n",
      "Highest Policy L1 Error: Index = 59, Value = 0.03772173821926117\n",
      "Highest Trajectory Error: Index = 172, Value = 0.2706121504306793\n",
      "Highest Goal Error: Index = 59, Value = 0.551712691783905\n",
      "-------------------------------------------------------------\n",
      "runs/Policies/09-10/run1-10-epochs/09-10-11-37-11-LPGTX_PretrainedImageEncoderAugmentedPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region (Goal Loss <= 0.009999999776482582): 4.0\n",
      "Average Policy L1 Loss: 0.015446171164512634\n",
      "Average Trajectory Loss: 0.0912640243768692\n",
      "Average Goal Loss: 0.12083584815263748\n",
      "Average Combined State Loss: 0.047838084399700165\n",
      "\n",
      "Least Policy L1 Error: Index = 297, Value = 0.0037895378191024065\n",
      "Least Trajectory Error: Index = 376, Value = 0.01775866560637951\n",
      "Least Goal Error: Index = 200, Value = 0.0040677511133253574\n",
      "\n",
      "Highest Policy L1 Error: Index = 157, Value = 0.059011198580265045\n",
      "Highest Trajectory Error: Index = 157, Value = 0.46388140320777893\n",
      "Highest Goal Error: Index = 157, Value = 1.0934815406799316\n",
      "\n",
      "Start processing checkpoint file runs/Policies/09-10/run1-10-epochs/09-10-12-32-12-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "-------------------------------------------------------------\n",
      "runs/Policies/09-10/run1-10-epochs/09-10-12-32-12-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region (Goal Loss <= 0.009999999776482582): 0.0\n",
      "Average Policy L1 Loss: 0.04790855571627617\n",
      "Average Trajectory Loss: 0.45901942253112793\n",
      "Average Goal Loss: 0.9687449336051941\n",
      "Average Combined State Loss: 0.23164935410022736\n",
      "\n",
      "Least Policy L1 Error: Index = 67, Value = 0.024199310690164566\n",
      "Least Trajectory Error: Index = 67, Value = 0.05203758180141449\n",
      "Least Goal Error: Index = 67, Value = 0.1016489639878273\n",
      "\n",
      "Highest Policy L1 Error: Index = 195, Value = 0.06182945519685745\n",
      "Highest Trajectory Error: Index = 7, Value = 0.9661149382591248\n",
      "Highest Goal Error: Index = 7, Value = 2.021524429321289\n",
      "-------------------------------------------------------------\n",
      "runs/Policies/09-10/run1-10-epochs/09-10-12-32-12-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region (Goal Loss <= 0.009999999776482582): 0.0\n",
      "Average Policy L1 Loss: 0.04825074225664139\n",
      "Average Trajectory Loss: 0.46144768595695496\n",
      "Average Goal Loss: 0.9738173484802246\n",
      "Average Combined State Loss: 0.23294107615947723\n",
      "\n",
      "Least Policy L1 Error: Index = 67, Value = 0.024199310690164566\n",
      "Least Trajectory Error: Index = 67, Value = 0.052037328481674194\n",
      "Least Goal Error: Index = 67, Value = 0.1016487255692482\n",
      "\n",
      "Highest Policy L1 Error: Index = 474, Value = 0.06603312492370605\n",
      "Highest Trajectory Error: Index = 7, Value = 0.96611487865448\n",
      "Highest Goal Error: Index = 7, Value = 2.021524429321289\n",
      "\n",
      "Start processing checkpoint file runs/Policies/09-10/run1-10-epochs/09-10-13-25-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "-------------------------------------------------------------\n",
      "runs/Policies/09-10/run1-10-epochs/09-10-13-25-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region (Goal Loss <= 0.009999999776482582): 0.0\n",
      "Average Policy L1 Loss: 0.018708735704421997\n",
      "Average Trajectory Loss: 0.11246737837791443\n",
      "Average Goal Loss: 0.16631585359573364\n",
      "Average Combined State Loss: 0.0583108514547348\n",
      "\n",
      "Least Policy L1 Error: Index = 147, Value = 0.0043035224080085754\n",
      "Least Trajectory Error: Index = 187, Value = 0.016221903264522552\n",
      "Least Goal Error: Index = 69, Value = 0.010693976655602455\n",
      "\n",
      "Highest Policy L1 Error: Index = 157, Value = 0.05006592720746994\n",
      "Highest Trajectory Error: Index = 60, Value = 0.3655278980731964\n",
      "Highest Goal Error: Index = 60, Value = 0.9034072756767273\n",
      "-------------------------------------------------------------\n",
      "runs/Policies/09-10/run1-10-epochs/09-10-13-25-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region (Goal Loss <= 0.009999999776482582): 7.0\n",
      "Average Policy L1 Loss: 0.01843123510479927\n",
      "Average Trajectory Loss: 0.11127205193042755\n",
      "Average Goal Loss: 0.16086097061634064\n",
      "Average Combined State Loss: 0.057745885103940964\n",
      "\n",
      "Least Policy L1 Error: Index = 147, Value = 0.004807460121810436\n",
      "Least Trajectory Error: Index = 345, Value = 0.018167052417993546\n",
      "Least Goal Error: Index = 492, Value = 0.005829491652548313\n",
      "\n",
      "Highest Policy L1 Error: Index = 335, Value = 0.059558212757110596\n",
      "Highest Trajectory Error: Index = 268, Value = 0.5803509950637817\n",
      "Highest Goal Error: Index = 294, Value = 1.2070980072021484\n",
      "\n",
      "Start processing checkpoint file runs/Policies/09-10/run1-10-epochs/09-10-14-26-17-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "-------------------------------------------------------------\n",
      "runs/Policies/09-10/run1-10-epochs/09-10-14-26-17-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region (Goal Loss <= 0.009999999776482582): 0.0\n",
      "Average Policy L1 Loss: 0.047837961465120316\n",
      "Average Trajectory Loss: 0.45910048484802246\n",
      "Average Goal Loss: 0.9672423601150513\n",
      "Average Combined State Loss: 0.23152318596839905\n",
      "\n",
      "Least Policy L1 Error: Index = 67, Value = 0.03381456807255745\n",
      "Least Trajectory Error: Index = 13, Value = 0.062078069895505905\n",
      "Least Goal Error: Index = 13, Value = 0.12858442962169647\n",
      "\n",
      "Highest Policy L1 Error: Index = 195, Value = 0.058345068246126175\n",
      "Highest Trajectory Error: Index = 7, Value = 0.95775306224823\n",
      "Highest Goal Error: Index = 7, Value = 1.9946222305297852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "runs/Policies/09-10/run1-10-epochs/09-10-14-26-17-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region (Goal Loss <= 0.009999999776482582): 0.0\n",
      "Average Policy L1 Loss: 0.048170410096645355\n",
      "Average Trajectory Loss: 0.4620392620563507\n",
      "Average Goal Loss: 0.9726554751396179\n",
      "Average Combined State Loss: 0.2331046164035797\n",
      "\n",
      "Least Policy L1 Error: Index = 67, Value = 0.03381456807255745\n",
      "Least Trajectory Error: Index = 13, Value = 0.062078021466732025\n",
      "Least Goal Error: Index = 13, Value = 0.1285843849182129\n",
      "\n",
      "Highest Policy L1 Error: Index = 488, Value = 0.06066841259598732\n",
      "Highest Trajectory Error: Index = 7, Value = 0.95775306224823\n",
      "Highest Goal Error: Index = 7, Value = 1.9946222305297852\n",
      "\n",
      "Start processing checkpoint file runs/Policies/09-10/run1-10-epochs/09-10-15-26-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "-------------------------------------------------------------\n",
      "runs/Policies/09-10/run1-10-epochs/09-10-15-26-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region (Goal Loss <= 0.009999999776482582): 0.0\n",
      "Average Policy L1 Loss: 0.047913890331983566\n",
      "Average Trajectory Loss: 0.460190087556839\n",
      "Average Goal Loss: 0.9695140719413757\n",
      "Average Combined State Loss: 0.23224684596061707\n",
      "\n",
      "Least Policy L1 Error: Index = 67, Value = 0.03257028013467789\n",
      "Least Trajectory Error: Index = 67, Value = 0.06471288949251175\n",
      "Least Goal Error: Index = 38, Value = 0.1298270970582962\n",
      "\n",
      "Highest Policy L1 Error: Index = 195, Value = 0.062453534454107285\n",
      "Highest Trajectory Error: Index = 7, Value = 0.8874914646148682\n",
      "Highest Goal Error: Index = 7, Value = 1.8486188650131226\n",
      "-------------------------------------------------------------\n",
      "runs/Policies/09-10/run1-10-epochs/09-10-15-26-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region (Goal Loss <= 0.009999999776482582): 0.0\n",
      "Average Policy L1 Loss: 0.048209235072135925\n",
      "Average Trajectory Loss: 0.4629668891429901\n",
      "Average Goal Loss: 0.9748132824897766\n",
      "Average Combined State Loss: 0.2335973083972931\n",
      "\n",
      "Least Policy L1 Error: Index = 67, Value = 0.03257028013467789\n",
      "Least Trajectory Error: Index = 67, Value = 0.06471288949251175\n",
      "Least Goal Error: Index = 38, Value = 0.1298270970582962\n",
      "\n",
      "Highest Policy L1 Error: Index = 195, Value = 0.062453534454107285\n",
      "Highest Trajectory Error: Index = 7, Value = 0.8874914646148682\n",
      "Highest Goal Error: Index = 7, Value = 1.8486188650131226\n",
      "\n",
      "Time Taken: 4844.248248338699 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for chkpt_file in utils.enumerate_files(rootdir='runs/Policies/09-10'):\n",
    "    print ('Start processing checkpoint file {}'.format(chkpt_file))\n",
    "    policy_takes_image=True # DO NOT FORGET TO SET THESE TWO\n",
    "    policy_takes_gtx=True\n",
    "    e = evaluator(chkpt_file, cpu, policy_takes_image=policy_takes_image, persist_to_disk=True, \n",
    "                  op_reverse_adapter=simplereacheradapters.Ut_scaled_adapter_zero_center_reverse,\n",
    "                  ip_adapter=simplereacheradapters.XtIt_scaled_adapter_eval,\n",
    "                  policy_takes_gtx=policy_takes_gtx\n",
    "                 )\n",
    "    e.evaluate(test_traj_data, target_folder='TestSet_Evaluations')\n",
    "    e.evaluate(train_traj_data, target_folder='SmallTrainSet_Evaluations')\n",
    "    print ('')\n",
    "\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/Policies/09-03/09-03-17-12-26-Train_PretrainedImageEncoderAndPolicy_EndToEnd-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "runs/Policies/09-03/09-03-17-36-35-Train_PretrainedImageEncoderAndAugmentedPolicy_EndToEnd-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "runs/Policies/09-03/09-03-17-59-48-Train_PretrainedImageEncoderAndTrigPolicy_EndToEnd-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "runs/Policies/09-03/09-03-18-22-58-FixImageEncoderPolicy_TrainDecoder-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "runs/Policies/09-03/09-03-18-40-33-FixImageEncoderAugmentedPolicy_TrainDecoder-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "runs/Policies/09-03/09-03-18-58-12-FixImageEncoderTrigPolicy_TrainDecoder-Reacher-Conv4Dense3-L1/train_checkpoint.tar\n",
      "Time Taken: 0.0025644302368164062 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for chkpt_file in utils.enumerate_files(rootdir='runs/Policies/09-03'):\n",
    "#     folder = os.path.join(os.path.dirname(chkpt_file), 'TestSet_Evaluations')\n",
    "#     if os.path.exists(folder):\n",
    "#         print ('Deleting folder : {}'.format(folder))\n",
    "#         shutil.rmtree(folder, ignore_errors=True)\n",
    "    print (chkpt_file)\n",
    "    os.rename(chkpt_file, chkpt_file+'.bkp')\n",
    "\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder : runs/Policies/09-10/run1-10-epochs/09-10-10-40-06-LPGTX_PretrainedImageEncoderPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1\n",
      "Processing folder : runs/Policies/09-10/run1-10-epochs/09-10-11-37-11-LPGTX_PretrainedImageEncoderAugmentedPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1\n",
      "Processing folder : runs/Policies/09-10/run1-10-epochs/09-10-12-32-12-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1\n",
      "Processing folder : runs/Policies/09-10/run1-10-epochs/09-10-13-25-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1\n",
      "Processing folder : runs/Policies/09-10/run1-10-epochs/09-10-14-26-17-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1\n",
      "Processing folder : runs/Policies/09-10/run1-10-epochs/09-10-15-26-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1\n",
      "Done\n",
      "Processing folder : runs/Policies/09-10/run1-10-epochs/09-10-10-40-06-LPGTX_PretrainedImageEncoderPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1\n",
      "Processing folder : runs/Policies/09-10/run1-10-epochs/09-10-11-37-11-LPGTX_PretrainedImageEncoderAugmentedPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1\n",
      "Processing folder : runs/Policies/09-10/run1-10-epochs/09-10-12-32-12-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1\n",
      "Processing folder : runs/Policies/09-10/run1-10-epochs/09-10-13-25-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1\n",
      "Processing folder : runs/Policies/09-10/run1-10-epochs/09-10-14-26-17-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1\n",
      "Processing folder : runs/Policies/09-10/run1-10-epochs/09-10-15-26-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "plottinghelpers.save_all_plots_policy_rollout_run(rootdir='runs/Policies/09-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From left to right:\n",
      "08-19-13-32-36-Policy-Reacher-Dense4WithTanh-L1\n",
      "08-19-20-24-49-FixImageEncoderPolicy_TrainDecoder-Reacher-Conv5Dense4-L1\n",
      "08-21-19-09-09-Policy-Reacher-Dense4WithTanh-L1\n",
      "08-22-10-38-38-Policy-Reacher-Dense4WithTanh-L1\n",
      "08-24-20-45-40-Policy_Augmented-Reacher-Dense4WithTanh-L1\n",
      "08-25-10-34-36-Policy_TrigAugmented-Reacher-Dense4WithTanh-L1\n",
      "08-25-14-03-35-FixImageEncoderAugmentedPolicy_TrainDecoder-Reacher-Conv5Dense4-L1\n",
      "08-25-20-26-27-FixImageEncoderTrigPolicy_TrainDecoder-Reacher-Conv5Dense4-L1\n",
      "08-31-16-35-49-Finetune_LowLR_FixImageEncoderTrigPolicy_TrainDecoder-Reacher-Conv5Dense4-L1\n",
      "08-31-21-05-50-Finetune_RegularLR_FixImageEncoderTrigPolicy_TrainDecoder-Reacher-Conv5Dense4-L1\n",
      "09-01-13-50-28-ImageToPolicy-Reacher-ComposedAutoEncoder5Dense-L1\n",
      "09-01-20-46-16-Train_ImageEncoderAndPolicy_EndToEnd-Reacher-Conv5Dense4-L1\n",
      "09-01-21-40-35-Train_ImageEncoderAndAugmentedPolicy_EndToEnd-Reacher-Conv5Dense4-L1\n",
      "09-01-22-34-02-Train_ImageEncoderAndTrigPolicy_EndToEnd-Reacher-Conv5Dense4-L1\n",
      "09-02-10-06-01-ImageToPolicy-Reacher-ImageEncoder4_16_3Dense3-L1\n",
      "09-03-17-12-26-Train_PretrainedImageEncoderAndPolicy_EndToEnd-Reacher-Conv4Dense3-L1\n",
      "09-09-16-16-41-LPGTX_FixImageEncoderPolicy_TrainDecoderToY-Reacher-Conv4Dense3-L1\n",
      "09-09-21-22-50-LPGTX_FixImageEncoderPolicy_TrainDecoderToY-Reacher-Conv4Dense3-L1\n",
      "09-10-01-03-19-LPGTX_FixImageEncoderAugmentedPolicy_TrainDecoderToY-Reacher-Conv4Dense3-L1\n",
      "09-10-10-40-06-LPGTX_PretrainedImageEncoderPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1\n",
      "09-10-11-37-11-LPGTX_PretrainedImageEncoderAugmentedPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1\n",
      "09-10-12-32-12-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1\n",
      "09-10-13-25-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_LowLR-Reacher-Conv4Dense3-L1\n",
      "09-10-14-26-17-LPGTX_RegularPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1\n",
      "09-10-15-26-59-LPGTX_AugmentedPolicyFinetuneEndToEnd_AfterDecoder_RegularLR-Reacher-Conv4Dense3-L1\n"
     ]
    }
   ],
   "source": [
    "plottinghelpers.box_plot_across_runs(\n",
    "    rootdir='runs/Policies',\n",
    "    eval_folder_name='TestSet_Evaluations',\n",
    "    error_index=4,\n",
    "    metric_name='Goal Deviation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From left to right:\n",
      "08-11-15-10-38-Policy-Reacher-Dense4WithTanh-L1\n",
      "08-11-15-45-41-Policy-Reacher-Dense4WithTanh-mse\n",
      "08-17-11-09-51-Policy-Reacher-Dense4WithTanh-mse\n",
      "08-17-14-49-24-Policy-Reacher-Dense4WithSigmoid-L1\n"
     ]
    }
   ],
   "source": [
    "plottinghelpers.box_plot_across_runs(\n",
    "    rootdir='runs/Policies',\n",
    "    eval_folder_name='TestSet_Evaluations',\n",
    "    error_index=4,\n",
    "    metric_name='Goal Deviation',\n",
    "    include=[\n",
    "        '08-11-15-10-38-Policy-Reacher-Dense4WithTanh-L1',\n",
    "        '08-11-15-45-41-Policy-Reacher-Dense4WithTanh-mse',\n",
    "        '08-17-11-09-51-Policy-Reacher-Dense4WithTanh-mse',\n",
    "        '08-17-14-49-24-Policy-Reacher-Dense4WithSigmoid-L1'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From left to right:\n",
      "08-19-13-32-36-Policy-Reacher-Dense4WithTanh-L1\n",
      "09-02-10-06-01-ImageToPolicy-Reacher-ImageEncoder4_16_3Dense3-L1\n",
      "09-03-17-12-26-Train_PretrainedImageEncoderAndPolicy_EndToEnd-Reacher-Conv4Dense3-L1\n",
      "09-10-11-37-11-LPGTX_PretrainedImageEncoderAugmentedPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1\n"
     ]
    }
   ],
   "source": [
    "plottinghelpers.box_plot_across_runs(\n",
    "    rootdir='runs/Policies',\n",
    "    eval_folder_name='TestSet_Evaluations',\n",
    "    error_index=4,\n",
    "    metric_name='Goal Deviation',\n",
    "    include=[\n",
    "        '08-19-13-32-36-Policy-Reacher-Dense4WithTanh-L1',\n",
    "        '09-02-10-06-01-ImageToPolicy-Reacher-ImageEncoder4_16_3Dense3-L1',\n",
    "        '09-03-17-12-26-Train_PretrainedImageEncoderAndPolicy_EndToEnd-Reacher-Conv4Dense3-L1',\n",
    "        '09-10-11-37-11-LPGTX_PretrainedImageEncoderAugmentedPolicy_TrainEndToEnd-Reacher-Conv4Dense3-L1'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From left to right:\n",
      "09-02-10-06-01-ImageToPolicy-Reacher-ImageEncoder4_16_3Dense3-L1\n",
      "08-14-08-54-19-FixImageEncoderPolicy_TrainDecoder-Reacher-Conv5Dense3-MSE\n",
      "08-19-20-24-49-FixImageEncoderPolicy_TrainDecoder-Reacher-Conv5Dense4-L1\n",
      "08-25-14-03-35-FixImageEncoderAugmentedPolicy_TrainDecoder-Reacher-Conv5Dense4-L1\n",
      "08-25-20-26-27-FixImageEncoderTrigPolicy_TrainDecoder-Reacher-Conv5Dense4-L1\n"
     ]
    }
   ],
   "source": [
    "plottinghelpers.box_plot_across_runs(\n",
    "    rootdir='runs/Policies',\n",
    "    eval_folder_name='TestSet_Evaluations',\n",
    "    error_index=4,\n",
    "    metric_name='Goal Deviation',\n",
    "    include=[\n",
    "        '09-02-10-06-01-ImageToPolicy-Reacher-ImageEncoder4_16_3Dense3-L1',\n",
    "        '08-14-08-54-19-FixImageEncoderPolicy_TrainDecoder-Reacher-Conv5Dense3-MSE',\n",
    "        '08-19-20-24-49-FixImageEncoderPolicy_TrainDecoder-Reacher-Conv5Dense4-L1',\n",
    "        '08-25-14-03-35-FixImageEncoderAugmentedPolicy_TrainDecoder-Reacher-Conv5Dense4-L1',\n",
    "        '08-25-20-26-27-FixImageEncoderTrigPolicy_TrainDecoder-Reacher-Conv5Dense4-L1'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From left to right:\n",
      "08-19-13-32-36-Policy-Reacher-Dense4WithTanh-L1\n",
      "08-13-11-15-00-FixImageToEnv_TrainFreshPolicy-Reacher-Conv4Dense3-MSE\n",
      "\n",
      "09-02-10-06-01-ImageToPolicy-Reacher-ImageEncoder4_16_3Dense3-L1\n"
     ]
    }
   ],
   "source": [
    "plottinghelpers.box_plot_across_runs(\n",
    "    rootdir='runs/Policies',\n",
    "    eval_folder_name='TestSet_Evaluations',\n",
    "    error_index=4,\n",
    "    metric_name='Goal Deviation',\n",
    "    include=[\n",
    "        '08-19-13-32-36-Policy-Reacher-Dense4WithTanh-L1',\n",
    "        '08-13-11-15-00-FixImageToEnv_TrainFreshPolicy-Reacher-Conv4Dense3-MSE',\n",
    "        '08-14-08-54-19-FixImageEncoderPolicy_TrainDecoder-Reacher-Conv4Dense3-MSE',\n",
    "        '09-02-10-06-01-ImageToPolicy-Reacher-ImageEncoder4_16_3Dense3-L1'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From left to right:\n",
      "08-19-13-32-36-Policy-Reacher-Dense4WithTanh-L1\n",
      "08-13-11-15-00-FixImageToEnv_TrainFreshPolicy-Reacher-Conv4Dense3-MSE\n"
     ]
    }
   ],
   "source": [
    "plottinghelpers.box_plot_across_runs(\n",
    "    rootdir='runs/Policies',\n",
    "    eval_folder_name='TestSet_Evaluations',\n",
    "    error_index=4,\n",
    "    metric_name='Goal Deviation',\n",
    "    include=[\n",
    "        '08-19-13-32-36-Policy-Reacher-Dense4WithTanh-L1',\n",
    "        '08-13-11-15-00-FixImageToEnv_TrainFreshPolicy-Reacher-Conv4Dense3-MSE',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From left to right:\n",
      "08-19-13-32-36-Policy-Reacher-Dense4WithTanh-L1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plottinghelpers.box_plot_across_runs(\n",
    "    rootdir='runs/Policies',\n",
    "    eval_folder_name='TestSet_Evaluations',\n",
    "    error_index=4,\n",
    "    metric_name='Goal Deviation',\n",
    "    include=[\n",
    "    '08-19-13-32-36-Policy-Reacher-Dense4WithTanh-L1',\n",
    "    '08-14-08-54-19-FixImageEncoderPolicy_TrainDecoder-Reacher-Conv4Dense3-MSE',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pol = load_pretrained('Policies/08-19/08-19-20-24-49-FixImageEncoderPolicy_TrainDecoder-Reacher-Conv5Dense4-L1')\n",
    "img_pol = img_pol.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = test_traj_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 65536])\n",
      "torch.Size([25, 3])\n",
      "tensor([[-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049],\n",
      "        [-0.0185, -0.0049,  0.0049]], grad_fn=<TanhBackward>)\n",
      "tensor([[-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010],\n",
      "        [-0.0037, -0.0010,  0.0010]], grad_fn=<MulBackward0>)\n",
      "tensor([[ 0.0212, -0.0462, -0.0826],\n",
      "        [ 0.0072, -0.0191,  0.0033],\n",
      "        [ 0.0319, -0.0847,  0.0339],\n",
      "        [ 0.0324, -0.0886,  0.0345],\n",
      "        [ 0.0324, -0.0894,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor(0.0489, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ip_data = simplereacheradapters.It_scaled_adapter(traj).float()\n",
    "op_data = img_pol(ip_data)\n",
    "print (ip_data.shape)\n",
    "print (op_data.shape)\n",
    "print (op_data)\n",
    "print (simplereacheradapters.Ut_scaled_adapter_zero_center_reverse(op_data))\n",
    "print (traj['states'][:, 6:])\n",
    "print (F.l1_loss(traj['states'][:, 6:], simplereacheradapters.Ut_scaled_adapter_zero_center_reverse(op_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_pol = pretrain_policy.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 6])\n",
      "torch.Size([25, 3])\n",
      "tensor([[ 0.1406, -0.4868,  0.1918],\n",
      "        [ 0.1373, -0.4714,  0.2155],\n",
      "        [ 0.1382, -0.4705,  0.2142],\n",
      "        [ 0.1430, -0.4702,  0.2030],\n",
      "        [ 0.1481, -0.4697,  0.1914],\n",
      "        [ 0.1533, -0.4690,  0.1796],\n",
      "        [ 0.1549, -0.4687,  0.1721],\n",
      "        [ 0.1541, -0.4660,  0.1732],\n",
      "        [ 0.1533, -0.4633,  0.1742],\n",
      "        [ 0.1525, -0.4606,  0.1753],\n",
      "        [ 0.1516, -0.4579,  0.1764],\n",
      "        [ 0.1607, -0.4558,  0.1676],\n",
      "        [ 0.1697, -0.4542,  0.1603],\n",
      "        [ 0.1748, -0.4532,  0.1597],\n",
      "        [ 0.1799, -0.4522,  0.1592],\n",
      "        [ 0.1803, -0.4524,  0.1577],\n",
      "        [ 0.1779, -0.4534,  0.1556],\n",
      "        [ 0.1756, -0.4543,  0.1535],\n",
      "        [ 0.1709, -0.4546,  0.1537],\n",
      "        [ 0.1618, -0.4481,  0.1652],\n",
      "        [ 0.1701, -0.4174,  0.1800],\n",
      "        [ 0.1784, -0.3858,  0.1948],\n",
      "        [ 0.1780, -0.3510,  0.2002],\n",
      "        [ 0.1190, -0.2753,  0.1424],\n",
      "        [ 0.0181, -0.0299,  0.0081]], grad_fn=<TanhBackward>)\n",
      "tensor([[ 0.0281, -0.0974,  0.0384],\n",
      "        [ 0.0275, -0.0943,  0.0431],\n",
      "        [ 0.0276, -0.0941,  0.0428],\n",
      "        [ 0.0286, -0.0940,  0.0406],\n",
      "        [ 0.0296, -0.0939,  0.0383],\n",
      "        [ 0.0307, -0.0938,  0.0359],\n",
      "        [ 0.0310, -0.0937,  0.0344],\n",
      "        [ 0.0308, -0.0932,  0.0346],\n",
      "        [ 0.0307, -0.0927,  0.0348],\n",
      "        [ 0.0305, -0.0921,  0.0351],\n",
      "        [ 0.0303, -0.0916,  0.0353],\n",
      "        [ 0.0321, -0.0912,  0.0335],\n",
      "        [ 0.0339, -0.0908,  0.0321],\n",
      "        [ 0.0350, -0.0906,  0.0319],\n",
      "        [ 0.0360, -0.0904,  0.0318],\n",
      "        [ 0.0361, -0.0905,  0.0315],\n",
      "        [ 0.0356, -0.0907,  0.0311],\n",
      "        [ 0.0351, -0.0909,  0.0307],\n",
      "        [ 0.0342, -0.0909,  0.0307],\n",
      "        [ 0.0324, -0.0896,  0.0330],\n",
      "        [ 0.0340, -0.0835,  0.0360],\n",
      "        [ 0.0357, -0.0772,  0.0390],\n",
      "        [ 0.0356, -0.0702,  0.0400],\n",
      "        [ 0.0238, -0.0551,  0.0285],\n",
      "        [ 0.0036, -0.0060,  0.0016]], grad_fn=<MulBackward0>)\n",
      "tensor([[ 0.0212, -0.0462, -0.0826],\n",
      "        [ 0.0072, -0.0191,  0.0033],\n",
      "        [ 0.0319, -0.0847,  0.0339],\n",
      "        [ 0.0324, -0.0886,  0.0345],\n",
      "        [ 0.0324, -0.0894,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0324, -0.0896,  0.0345],\n",
      "        [ 0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n",
      "tensor(0.0076, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ip_data = simplereacheradapters.XtYt_scaled_adapter(traj).float()\n",
    "print (ip_data.shape)\n",
    "op_data = ld_pol(ip_data)\n",
    "print (op_data.shape)\n",
    "print (op_data)\n",
    "print (simplereacheradapters.Ut_scaled_adapter_zero_center_reverse(op_data))\n",
    "print (traj['states'][:, 6:])\n",
    "print (F.l1_loss(traj['states'][:, 6:], simplereacheradapters.Ut_scaled_adapter_zero_center_reverse(op_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trajectories where there is goal deviation in ground truth : 229\n",
      "Maximum goal deviation in ground truth : 0.033625187543541234\n"
     ]
    }
   ],
   "source": [
    "traj_data = SimpleReacherTrajectoryDataset(root_folder, range(5000), device=cpu)\n",
    "count = 0\n",
    "max_dev = 0\n",
    "for tId in range(len(traj_data)):\n",
    "    last_row = traj_data[tId][states_key][-1, :]\n",
    "    goal_dev_gt = F.l1_loss(last_row[:3], last_row[3:6])\n",
    "    if goal_dev_gt > 0.01:\n",
    "        # print (goal_dev_gt)\n",
    "        max_dev = max(max_dev, goal_dev_gt)\n",
    "        count += 1\n",
    "print ('Total trajectories where there is goal deviation in ground truth : {}'.format(count))\n",
    "print ('Maximum goal deviation in ground truth : {}'.format(max_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "expts = [\n",
    "#   Image to Policy: Use pretrained image encoder, policy, train decoder/end-to-end \n",
    "#     [{\n",
    "#         \"expt_prefix\":'Finetune_LowLR_FixImageEncoderTrigPolicy_TrainDecoder-Reacher-Conv5Dense4-L1',\n",
    "#         \"net_func\": lambda: finetune_pretrained('Policies/08-19/08-19-20-24-49-FixImageEncoderPolicy_TrainDecoder-Reacher-Conv5Dense4-L1'),\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#         \"optimizer_func\": lambda net: optim.Adam(net.parameters(), lr=1e-4)\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'Finetune_RegularLR_FixImageEncoderTrigPolicy_TrainDecoder-Reacher-Conv5Dense4-L1',\n",
    "#         \"net_func\": lambda: finetune_pretrained('Policies/08-19/08-19-20-24-49-FixImageEncoderPolicy_TrainDecoder-Reacher-Conv5Dense4-L1'),\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'Train_PretrainedImageEncoderAndPolicy_EndToEnd-Reacher-Conv4Dense3-L1',\n",
    "#         \"net_func\": lambda: latent_policy_pretrained_img_enc_pol_train_end_to_end\n",
    "#             (i_encoder=img_encoder_4_16_3, \n",
    "#              e_decoder=lambda: Dense([4096, 512, 6], last_act='sigmoid', prefix='envdec'),\n",
    "#              policy=pretrain_policy\n",
    "#             ),\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'Train_PretrainedImageEncoderAndAugmentedPolicy_EndToEnd-Reacher-Conv4Dense3-L1',\n",
    "#         \"net_func\": lambda: latent_policy_pretrained_img_enc_pol_train_end_to_end\n",
    "#             (i_encoder=img_encoder_4_16_3, \n",
    "#              e_decoder=lambda: Dense([4096, 512, 9], last_act='sigmoid', prefix='envdec'),\n",
    "#              policy=pretrain_pol_augmented\n",
    "#             ),\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'Train_PretrainedImageEncoderAndTrigPolicy_EndToEnd-Reacher-Conv4Dense3-L1',\n",
    "#         \"net_func\": lambda: latent_policy_pretrained_img_enc_pol_train_end_to_end\n",
    "#             (i_encoder=img_encoder_4_16_3, \n",
    "#              e_decoder=lambda: Dense([4096, 512, 12], last_act='sigmoid', prefix='envdec'),\n",
    "#              policy=pretrain_pol_trig\n",
    "#             ),\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "\n",
    "#     [{\n",
    "#         \"expt_prefix\":'FixImageEncoderPolicy_TrainDecoder-Reacher-Conv4Dense3-L1',\n",
    "#         \"net_func\": lambda: latent_policy_fixed_img_enc_pol_train_env_dec\n",
    "#             (i_encoder=img_encoder_4_16_3, \n",
    "#              e_decoder=lambda: Dense([4096, 512, 6], last_act='sigmoid', prefix='envdec'),\n",
    "#              policy=pretrain_policy\n",
    "#             ),\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'FixImageEncoderAugmentedPolicy_TrainDecoder-Reacher-Conv4Dense3-L1',\n",
    "#         \"net_func\": lambda: latent_policy_fixed_img_enc_pol_train_env_dec\n",
    "#             (i_encoder=img_encoder_4_16_3, \n",
    "#              e_decoder=lambda: Dense([4096, 512, 9], last_act='sigmoid', prefix='envdec'),\n",
    "#              policy=pretrain_pol_augmented\n",
    "#             ),\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'FixImageEncoderTrigPolicy_TrainDecoder-Reacher-Conv4Dense3-L1',\n",
    "#         \"net_func\": lambda: latent_policy_fixed_img_enc_pol_train_env_dec\n",
    "#             (i_encoder=img_encoder_4_16_3, \n",
    "#              e_decoder=lambda: Dense([4096, 512, 12], last_act='sigmoid', prefix='envdec'),\n",
    "#              policy=pretrain_pol_trig\n",
    "#             ),\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#   Train policy using fixed Image To Env function\n",
    "#     [{\n",
    "#         \"expt_prefix\":'FixImageToEnv_TrainFreshPolicy-Reacher-Conv4Dense3-MSE',\n",
    "#         \"net_func\": lambda: latent_policy_from_latent(pretrain_img_to_env),\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": mse_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#   Image To Env function\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageToEnv-Reacher-Conv4Dense3-MSE',\n",
    "#         \"net_func\": lambda: image_to_env(img_encoder, env_decoder),\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.XtYt_scaled_adapter,\n",
    "#         \"loss_adapter_func\": mse_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#   Policy\n",
    "#     [{\n",
    "#         \"expt_prefix\":'Policy-Reacher-Dense4WithTanh-L1',\n",
    "#         \"net_func\": lambda: Dense(layer_dims=[6, 16, 16, 3], last_act='tanh', prefix='pol'),\n",
    "#         \"data_adapter_func\": simplereacheradapters.XtYt_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'Policy_Augmented-Reacher-Dense4WithTanh-L1',\n",
    "#         \"net_func\": lambda: Dense(layer_dims=[9, 16, 16, 3], last_act='tanh', prefix='pol'),\n",
    "#         \"data_adapter_func\": simplereacheradapters.Xt_XtYt_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'Policy_TrigAugmented-Reacher-Dense4WithTanh-L1',\n",
    "#         \"net_func\": lambda: Dense(layer_dims=[12, 16, 16, 3], last_act='tanh', prefix='pol'),\n",
    "#         \"data_adapter_func\": simplereacheradapters.XtYt_trig_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#   Image to policy : Direct\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageToPolicy-Reacher-ComposedAutoEncoder5Dense-L1',\n",
    "#         \"net_func\": lambda: combined(img_encoder_5_32_5, lambda: Dense(layer_dims=[2048, 512, 128, 3], last_act='tanh', prefix='pol')), \n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageToPolicy-Reacher-ComposedAutoEncoder5Dense-L1',\n",
    "#         \"net_func\": lambda: combined(img_encoder_5_32_5, lambda: Dense(layer_dims=[2048, 512, 3], last_act='tanh', prefix='pol')), \n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageToPolicy-Reacher-ImageEncoder4_16_3Dense3-L1',\n",
    "#         \"net_func\": lambda: combined(img_encoder_4_16_3, lambda: Dense(layer_dims=[4096, 512, 3], last_act='tanh', prefix='pol')), \n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageToPolicy-Reacher-ComposedAutoEncoder5Dense-L1',\n",
    "#         \"net_func\": lambda: combined(img_encoder_5_32_7, lambda: Dense(layer_dims=[2048, 512, 3], last_act='tanh', prefix='pol')), \n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": simplereacheradapters.Ut_scaled_adapter_zero_center,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#   Image autoencoder\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageAutoEncoder-Reacher-ComposedAutoEncoder4-MSE',\n",
    "#         \"net_func\": img_auto_encoder,\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"loss_adapter_func\": mse_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageAutoEncoder-Reacher-ComposedAutoEncoder4-L1',\n",
    "#         \"net_func\": img_auto_encoder_4_16_3,\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_16_7-L1',\n",
    "#         \"net_func\": img_auto_encoder_5_16_7,\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_32_7-L1',\n",
    "#         \"net_func\": img_auto_encoder_5_32_7,\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_16_5-L1',\n",
    "#         \"net_func\": img_auto_encoder_5_16_5,\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'ImageAutoEncoder-Reacher-ComposedAutoEncoder_5_32_5-L1',\n",
    "#         \"net_func\": img_auto_encoder_5_32_5,\n",
    "#         \"data_adapter_func\": simplereacheradapters.It_scaled_adapter,\n",
    "#         \"loss_adapter_func\": l1_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": l1_loss_adapter\n",
    "#     }],\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
