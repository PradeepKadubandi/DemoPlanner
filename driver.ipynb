{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import pprint\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "from adapters import *\n",
    "from dataset import NumpyCsvDataSet\n",
    "from runner import ExptRunner\n",
    "from networks.imageencoder import *\n",
    "from networks.imagedecoder import *\n",
    "from networks.DenseAutoEncoder import DenseAutoEncoder\n",
    "from networks.composedautoencoder import ComposedAutoEncoder\n",
    "from networks.ConvVae import ConvVae\n",
    "from networks.vae import VAE\n",
    "from networks.dense import *\n",
    "from networks.lossfunctions import *\n",
    "from networks.multinet import *\n",
    "from networks.special import *\n",
    "from helpers import *\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't know how to reset  control_ce_loss_adapter, please run `%reset?` for details\n"
     ]
    }
   ],
   "source": [
    "%reset -f control_ce_loss_adapter\n",
    "from networks.lossfunctions import control_ce_loss_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=torch.serialization.SourceChangeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = np.get_printoptions()\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print (torch.cuda.current_device())\n",
    "    torch.cuda.set_device(device)\n",
    "    print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 36.17111396789551 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_folder = 'data/demoplanner/version1'\n",
    "v1_train_data = NumpyCsvDataSet(data_folder + '/train.csv', device=device)\n",
    "v1_test_data = NumpyCsvDataSet(data_folder + '/test.csv', device=device)\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 283.2419309616089 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_folder = 'data/demoplanner/version2'\n",
    "v2_train_data = NumpyCsvDataSet(data_folder + '/train.csv', device=device)\n",
    "v2_test_data = NumpyCsvDataSet(data_folder + '/test.csv', device=device)\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = v1_train_data\n",
    "test_data = v1_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13280, 2058])\n",
      "cpu\n",
      "torch.float32\n",
      "cpu\n",
      "torch.Size([1341, 2058])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print (train_data.data.shape)\n",
    "print (train_data.data.device)\n",
    "print (train_data.data.dtype)\n",
    "\n",
    "print (test_data.data.device)\n",
    "print (test_data.data.shape)\n",
    "print (test_data.data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained(folder):\n",
    "    chkptFile = 'runs/pretrained/' + folder + '/train_checkpoint.tar'\n",
    "    return torch.load(chkptFile, map_location=device)['model']\n",
    "\n",
    "pretrain_policy = Dense([4, 16, 16, 6], use_last_act=False, prefix='enc').to(device)\n",
    "pretrain_policy.load_state_dict(torch.load('runs/pretrained/04-08-10-24-50-Policy-V2-Dense-CE/autoenc.pth', \n",
    "                                  map_location=device))\n",
    "\n",
    "pretrain_dynamics = Dense([4, 16, 2], prefix='enc').to(device)\n",
    "pretrain_dynamics.load_state_dict(torch.load('runs/pretrained/03-31-18-02-52-Dynamics-V1-Dense-SmoothL1/autoenc.pth', \n",
    "                                    map_location=device))\n",
    "\n",
    "pretrain_imgEncDec = ComposedAutoEncoder(layers_channels=[16,16,16,16], useMaxPool=True, device=device).to(device)\n",
    "pretrain_imgEncDec.load_state_dict(torch.load('runs/pretrained/03-28-14-10-20-DemoPl-V2-ComposedAutoEncoderWithMaxPool-SmoothL1-/autoenc.pth',\n",
    "                               map_location=device))\n",
    "\n",
    "pretrain_envEncDec = load_pretrained('04-20-11-03-59-EnvAutoEnc-V2-DenseAutoEncoder-MSE')\n",
    "pretrain_ImgToEnvBaseLine = load_pretrained('04-21-12-51-48-ImageToEnvFunctionBaseLine-V2-3Conv2Dense-MSE')\n",
    "latentModel0422 = load_pretrained('04-22-23-59-35-TriLossOnCombinedNet-V2-ImageEnvEncoder-MSE_Adam')\n",
    "latentModel0427 = load_pretrained('04-27-21-54-52-QuadLossOnCombinedNet-V2-MultiNet-MSE')\n",
    "\n",
    "pretrain_policy_augmented_y = load_pretrained('06-20-12-42-08-TrainPolicyUsingAugmentedY-V2-Dense-CE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_builder = lambda: MultiNet(policy=Dense([4, 16, 16, 6], use_last_act=False),\n",
    "                               dynamics=Dense([4, 16, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_layers = [16,16,16,16]\n",
    "z_dim = 64 # This should be set based on above img_layers\n",
    "env_layers = [4, 256, z_dim]\n",
    "in_channels = 1\n",
    "img_encoder = lambda: ImageEncoderFlatInput(in_channels, img_layers, 'imgenc', useMaxPool=True, addFlatten=True)\n",
    "img_decoder = lambda: ImageDecoderFlatInput(z_dim, list(reversed(img_layers)), in_channels, 'imgdec', useSigmoid=True)\n",
    "env_encoder = lambda: Dense(env_layers, use_last_act=False, prefix='envenc')\n",
    "env_decoder = lambda: Dense(list(reversed(env_layers)), last_act='sigmoid', prefix='envdec')\n",
    "combined = lambda l1, l2: nn.Sequential(OrderedDict([\n",
    "                              ('EncNet', l1()),\n",
    "                              ('DecNet', l2()),\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_enc_pretrained_img_dec():\n",
    "    net = combined(env_encoder, img_decoder).to(device)\n",
    "    load_mapped_state_dict(net, pretrain_imgEncDec, 'DecNet.net.imgdec', 'decoder.net.dec')\n",
    "    return net\n",
    "\n",
    "def pretrained_img_enc_env_dec(env_decoder):\n",
    "    net = combined(img_encoder, env_decoder).to(device)\n",
    "    load_mapped_state_dict(net, pretrain_imgEncDec, 'EncNet.net.imgenc', 'encoder.net.enc')\n",
    "    return net\n",
    "\n",
    "def img_enc_env_dec_from_pretrained():\n",
    "    net = combined(img_encoder, env_decoder).to(device)\n",
    "    load_mapped_state_dict(net, pretrain_imgEncDec, 'EncNet.net.imgenc', 'encoder.net.enc')\n",
    "    load_mapped_state_dict(net, pretrain_envEncDec, 'DecNet.net.envdec_fc0', 'decoder.dec_fc1') # Hacky\n",
    "    return net\n",
    "\n",
    "def multinet_with_pretrained_policy_and_dynamics():\n",
    "    net = MultiNet(policy=Dense([4, 16, 16, 6], use_last_act=False, prefix='enc'),\n",
    "                   dynamics=Dense([4, 16, 2], prefix='enc')).to(device)\n",
    "    net.policy.load_state_dict(pretrain_policy.state_dict())\n",
    "    net.dynamics.load_state_dict(pretrain_dynamics.state_dict())\n",
    "    return net\n",
    "\n",
    "def image_to_env(conv, dense):\n",
    "    return nn.Sequential(OrderedDict([\n",
    "        ('Conv', conv),\n",
    "        ('Dense', dense)\n",
    "    ])).to(device)\n",
    "\n",
    "def end_to_end_net():\n",
    "    ItoY = image_to_env(ImageEncoderFlatInput(1, [16,16,16], prefix='imgenc', useMaxPool=True, addFlatten=True),\n",
    "                     Dense([256, 4])).to(device)\n",
    "    policy = Dense([4, 16, 16, 6], use_last_act=False, prefix='pol').to(device)\n",
    "    dynamics = Dense([4, 16, 2], prefix='dyn').to(device)\n",
    "    net = EndToEndNet(ItoY=ItoY, policy=policy, dynamics=dynamics).to(device)\n",
    "    return net\n",
    "\n",
    "def end_to_end_net_from_pretrained(pretrain_indices=[], fix_indices=[]):\n",
    "    net = end_to_end_net()\n",
    "    if 1 in pretrain_indices:\n",
    "        load_mapped_state_dict(net, pretrain_policy, 'policy.net.pol', 'net.enc')\n",
    "    if 2 in pretrain_indices:\n",
    "        load_mapped_state_dict(net, pretrain_dynamics, 'dynamics.net.dyn', 'net.enc')\n",
    "    if 0 in pretrain_indices:\n",
    "        load_mapped_state_dict(net, pretrain_ImgToEnvBaseLine, 'ItoY.Conv', 'Conv')\n",
    "        load_mapped_state_dict(net, pretrain_ImgToEnvBaseLine, 'ItoY.Dense', 'Dense')\n",
    "    net.configureTraining(filters=fix_indices)\n",
    "    return net\n",
    "\n",
    "def latent_policy_from_latent(latentReference, policy=None, fix_indices=[0]):\n",
    "    latent = copy.deepcopy(latentReference)\n",
    "    if not policy:\n",
    "        policy = Dense([64, 16, 6], use_last_act=False, prefix='pol')\n",
    "    net = LatentPolicyNet(latent=latent, policy=policy).to(device)\n",
    "    net.configureTraining(filters=fix_indices)\n",
    "    return net\n",
    "\n",
    "def latent_policy_fixed_img_enc_pol_train_env_dec(latentFilter=None, policy=pretrain_policy, env_decoder=env_decoder):\n",
    "    latent = pretrained_img_enc_env_dec(env_decoder)\n",
    "    policy = copy.deepcopy(policy)\n",
    "    configure_net_training(policy, False)\n",
    "    configure_net_training(latent[0], False)\n",
    "    return LatentPolicyNet(latent=latent, policy=policy, latentFilter=latentFilter).to(device)\n",
    "\n",
    "def latentFilter_gt_x_latent_y(data, latent_output):\n",
    "    return torch.cat((Xt_scaled_adapter(data), latent_output[:, 2:]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentPolicyNet(\n",
       "  (latent): Sequential(\n",
       "    (EncNet): ImageEncoderFlatInput(\n",
       "      (net): Sequential(\n",
       "        (imgenc_conv0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (imgenc_relu0): ReLU()\n",
       "        (imgenc_maxpool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (imgenc_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (imgenc_relu1): ReLU()\n",
       "        (imgenc_maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (imgenc_conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (imgenc_relu2): ReLU()\n",
       "        (imgenc_maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (imgenc_conv3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (imgenc_relu3): ReLU()\n",
       "        (imgenc_maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (imgenc_flat): Flatten()\n",
       "      )\n",
       "      (reshapeInput): Reshape()\n",
       "    )\n",
       "    (DecNet): Dense(\n",
       "      (net): Sequential(\n",
       "        (envdec_fc0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (envdec_relu0): ReLU()\n",
       "        (envdec_fc1): Linear(in_features=256, out_features=4, bias=True)\n",
       "        (envdec_sig1): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (policy): Dense(\n",
       "    (net): Sequential(\n",
       "      (enc_fc0): Linear(in_features=4, out_features=16, bias=True)\n",
       "      (enc_relu0): ReLU()\n",
       "      (enc_fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (enc_relu1): ReLU()\n",
       "      (enc_fc2): Linear(in_features=16, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = latent_policy_fixed_img_enc_pol_train_env_dec(latentFilter=latentFilter_gt_x_latent_y, policy=pretrain_policy_augmented_y)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 3, 3]):False\n",
      "torch.Size([16]):False\n",
      "torch.Size([16, 16, 3, 3]):False\n",
      "torch.Size([16]):False\n",
      "torch.Size([16, 16, 3, 3]):False\n",
      "torch.Size([16]):False\n",
      "torch.Size([16, 16, 3, 3]):False\n",
      "torch.Size([16]):False\n",
      "torch.Size([256, 64]):True\n",
      "torch.Size([256]):True\n",
      "torch.Size([4, 256]):True\n",
      "torch.Size([4]):True\n",
      "torch.Size([16, 4]):False\n",
      "torch.Size([16]):False\n",
      "torch.Size([16, 16]):False\n",
      "torch.Size([16]):False\n",
      "torch.Size([6, 16]):False\n",
      "torch.Size([6]):False\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    print ('{}:{}'.format(p.size(), p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_expts(train_epochs):\n",
    "    for i in range(len(expts)):\n",
    "        arg_lists = expts[i]\n",
    "        cons_args = arg_lists[0]\n",
    "        train_args = {}\n",
    "        if (len(arg_lists)) > 1:\n",
    "            train_args = arg_lists[1]\n",
    "        test_args = {}\n",
    "        if (len(arg_lists)) > 2:\n",
    "            test_args = arg_lists[2]\n",
    "        \n",
    "        runner = ExptRunner(train_data=train_data, test_data=test_data, device=device, **cons_args)\n",
    "        print (\"Experiment logs folder: {}\".format(runner.log_folder))\n",
    "        with open(runner.log_folder + '/expt.txt', 'w') as f:\n",
    "            f.write(pprint.pformat(arg_lists))\n",
    "        runner.train(train_epochs, **train_args)\n",
    "        runner.test(**test_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "expts = [\n",
    "#     [{\n",
    "#         \"expt_prefix\":'Fix_ImagEnc_AugmentedPolicy_Train_EnvDec-V2-LatentPolicyNet-CE',\n",
    "#         \"net_func\": lambda: latent_policy_fixed_img_enc_pol_train_env_dec(latentFilter=latentFilter_gt_x_latent_y, policy=pretrain_policy_augmented_y),\n",
    "#         \"data_to_label_adapter\": policy_groud_truth_class_adapter,\n",
    "#         \"loss_adapter_func\": control_ce_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": policy_l1_loss_adapter\n",
    "#     }],\n",
    "    [{\n",
    "        \"expt_prefix\":'Finetune-0616232643-V2-LatentPolicyNet-CE',\n",
    "        \"net_func\": lambda: net,\n",
    "        \"data_to_label_adapter\": policy_groud_truth_class_adapter,\n",
    "        \"loss_adapter_func\": control_ce_loss_adapter,\n",
    "     },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "        \"loss_adapter\": policy_l1_loss_adapter\n",
    "    }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'TrainPolicyUsingAugmentedY-V2-Dense-CE',\n",
    "#         \"net_func\": lambda: Dense([6, 16, 16, 6], use_last_act=False, prefix='pol'),\n",
    "#         \"data_adapter_func\": Xt_XtYt_scaled_adapter,\n",
    "#         \"data_to_label_adapter\": policy_groud_truth_class_adapter,\n",
    "#         \"loss_adapter_func\": control_ce_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": policy_l1_loss_adapter\n",
    "#     }],\n",
    "#     [{\n",
    "#         \"expt_prefix\":'InitAndFixLatentTrainPolicy-V2-LatentPolicyNet-CE',\n",
    "#         \"net_func\": lambda: latent_policy_from_latent(latentModel0422.imgEnc, policy=Dense([64, 6], use_last_act=False, prefix='pol')),\n",
    "#         \"data_to_label_adapter\": policy_groud_truth_class_adapter,\n",
    "#         \"loss_adapter_func\": control_ce_loss_adapter,\n",
    "#      },\n",
    "#     {\n",
    "#     },\n",
    "#     {\n",
    "#         \"loss_adapter\": policy_l1_loss_adapter\n",
    "#     }],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs = 150\n",
    "run_expts(train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = ExptRunner('ForTestReport', net_func= lambda:net, train_data=train_data, test_data=test_data, device=device,\n",
    "                    loss_adapter_func=None, data_adapter_func=chkpt['input_adapter'], data_to_label_adapter=chkpt['label_adapter'])\n",
    "print (\"Experiment logs folder: {}\".format(runner.log_folder))\n",
    "runner.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reporter(checkpoint_file, useL1Loss=True):\n",
    "    rr = ReportResults(test_data.data, train_data.data, device,\n",
    "                       checkpoint_file, useL1Loss)\n",
    "    return rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_net_report(checkpoint_file):\n",
    "    cp = torch.load(checkpoint_file, map_location=device)\n",
    "    net = cp['model']\n",
    "    se = SpecialExptRunner('', net, None, test_data, device=device)\n",
    "    se.eval_end_of_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.cat((test_data.data[1055:1060], test_data.data[1230:1235]), axis=0)\n",
    "ground_truth = policy_groud_truth_class_adapter(sample).to(device)\n",
    "for folder, net in rr.build_net(rootdir='runs/04-07/'):\n",
    "    print ('Folder: ' + folder)\n",
    "    op_batch, loss = rr.run_mini_batch(net, sample)\n",
    "    x_loss = F.cross_entropy(op_batch[:, :3], ground_truth[:, 0], reduction='none')\n",
    "    y_loss = F.cross_entropy(op_batch[:, 3:], ground_truth[:, 1], reduction='none')\n",
    "    print (ground_truth)\n",
    "    print (op_batch)\n",
    "    print (loss)\n",
    "    print (x_loss)\n",
    "    print (y_loss)\n",
    "    print ('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.cat((test_data.data[1055:1060], test_data.data[1230:1235]), axis=0)\n",
    "ground_truth = policy_groud_truth_adapter(sample).to(device)\n",
    "for folder, net in rr.build_net(rootdir='runs/04-08/'):\n",
    "    print ('Folder: ' + folder)\n",
    "    op_batch, loss = rr.run_mini_batch(net, sample)\n",
    "    print (ground_truth)\n",
    "    print (op_batch)\n",
    "    print (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(**opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demopl",
   "language": "python",
   "name": "demopl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
