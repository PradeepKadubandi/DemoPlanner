{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from adapters import *\n",
    "from dataset import NumpyCsvDataSet\n",
    "from runner import ExptRunner\n",
    "from networks.autoencoder import AutoEncoder\n",
    "from networks.composedautoencoder import ComposedAutoEncoder\n",
    "from networks.DenseAutoEncoder import DenseAutoEncoder\n",
    "from networks.ConvVae import ConvVae\n",
    "from networks.vae import VAE\n",
    "from networks.etpr.autoencoder import autoencoder as etprautoenc\n",
    "from networks.dense import Dense\n",
    "from networks.dense import DenseForPolicy\n",
    "from networks.imageencoder import ImageEncoder\n",
    "from networks.multinet import *\n",
    "from networks.lossfunctions import *\n",
    "from helpers import ReportResults\n",
    "from policyeval import PolicyEvaluator\n",
    "from policyeval import eval_policy_accuracy\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=torch.serialization.SourceChangeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = np.get_printoptions()\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 2.3487699031829834 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_folder = 'data/demoplanner/version1'\n",
    "# v1_train_data = NumpyCsvDataSet(data_folder + '/train.csv', device=device)\n",
    "v1_test_data = NumpyCsvDataSet(data_folder + '/test.csv', device=device)\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 11.170909881591797 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_folder = 'data/demoplanner/version2'\n",
    "# v2_train_data = NumpyCsvDataSet(data_folder + '/train.csv', device=device)\n",
    "v2_test_data = NumpyCsvDataSet(data_folder + '/test.csv', device=device)\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = v2_test_data.data\n",
    "# train_data = v2_train_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6648, 2058])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# print (train_data.shape)\n",
    "# print (train_data.device)\n",
    "\n",
    "print (test_data.shape)\n",
    "print (test_data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 22, 31, 34, 43, 50, 70, 86, 90, 106, 114, 122, 138, 152, 157, 173, 184, 191, 211, 219, 224, 226, 249, 260, 269, 279, 290, 307, 324, 340, 355, 367, 376, 400, 412, 426, 436, 453, 474, 485, 489, 509, 530, 536, 545, 554, 579, 597, 608, 621, 643, 651, 656, 664, 676, 683, 692, 706, 713, 740, 759, 774, 792, 802, 819, 841, 853, 878, 898, 905, 914, 925, 934, 944, 954, 974, 984, 998, 1007, 1008, 1015, 1025, 1043, 1061, 1065, 1089, 1094, 1103, 1114, 1126, 1129, 1152, 1160, 1177, 1183, 1196, 1207, 1232, 1243, 1265, 1274, 1293, 1302, 1316, 1328, 1350, 1358, 1371, 1375, 1397, 1402, 1422, 1439, 1442, 1454, 1461, 1481, 1500, 1516, 1536, 1550, 1559, 1565, 1577, 1601, 1626, 1645, 1669, 1681, 1694, 1702, 1720, 1729, 1738, 1753, 1777, 1792, 1793, 1794, 1802, 1814, 1818, 1836, 1842, 1865, 1887, 1909, 1915, 1925, 1931, 1941, 1963, 1979, 1998, 2023, 2042, 2068, 2093, 2096, 2106, 2124, 2136, 2149, 2160, 2180, 2194, 2206, 2213, 2236, 2242, 2248, 2260, 2269, 2291, 2304, 2312, 2322, 2336, 2350, 2360, 2380, 2392, 2399, 2412, 2414, 2427, 2440, 2459, 2475, 2489, 2493, 2509, 2523, 2533, 2548, 2561, 2583, 2588, 2604, 2616, 2635, 2660, 2672, 2679, 2687, 2692, 2704, 2718, 2725, 2734, 2758, 2768, 2780, 2795, 2807, 2817, 2821, 2836, 2847, 2860, 2878, 2893, 2915, 2931, 2944, 2948, 2962, 2980, 2989, 3013, 3022, 3025, 3031, 3034, 3047, 3061, 3084, 3095, 3108, 3120, 3126, 3149, 3168, 3176, 3200, 3223, 3231, 3248, 3252, 3267, 3281, 3306, 3329, 3352, 3369, 3384, 3400, 3415, 3438, 3457, 3466, 3471, 3484, 3493, 3500, 3512, 3523, 3526, 3534, 3554, 3555, 3563, 3570, 3577, 3593, 3609, 3619, 3639, 3647, 3657, 3675, 3688, 3706, 3731, 3743, 3764, 3774, 3793, 3810, 3834, 3846, 3862, 3875, 3878, 3883, 3887, 3894, 3897, 3910, 3927, 3944, 3947, 3968, 3993, 4015, 4021, 4031, 4044, 4063, 4072, 4080, 4086, 4104, 4123, 4147, 4166, 4180, 4192, 4216, 4234, 4250, 4266, 4285, 4300, 4319, 4339, 4354, 4355, 4363, 4374, 4396, 4400, 4414, 4421, 4435, 4457, 4482, 4492, 4497, 4501, 4513, 4525, 4540, 4553, 4567, 4577, 4586, 4601, 4608, 4616, 4625, 4635, 4640, 4646, 4667, 4675, 4680, 4695, 4704, 4727, 4742, 4756, 4777, 4793, 4801, 4803, 4816, 4820, 4838, 4849, 4867, 4882, 4902, 4920, 4935, 4948, 4969, 4995, 5004, 5012, 5037, 5059, 5083, 5105, 5125, 5133, 5146, 5171, 5184, 5206, 5215, 5233, 5247, 5253, 5274, 5285, 5302, 5319, 5329, 5347, 5363, 5365, 5382, 5400, 5410, 5432, 5446, 5464, 5472, 5481, 5503, 5508, 5521, 5531, 5553, 5558, 5571, 5583, 5590, 5612, 5621, 5636, 5646, 5650, 5658, 5677, 5692, 5708, 5729, 5739, 5746, 5760, 5768, 5789, 5805, 5828, 5853, 5860, 5875, 5882, 5893, 5919, 5931, 5952, 5958, 5964, 5978, 5989, 6008, 6030, 6050, 6070, 6076, 6079, 6089, 6100, 6114, 6135, 6144, 6153, 6161, 6163, 6187, 6197, 6209, 6219, 6228, 6236, 6253, 6265, 6280, 6288, 6303, 6314, 6327, 6336, 6339, 6342, 6358, 6363, 6371, 6389, 6403, 6415, 6437, 6450, 6462, 6485, 6504, 6519, 6520, 6534, 6551, 6564, 6580, 6586, 6596, 6602, 6624, 6635]\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "t_cpu = test_data.data.cpu()\n",
    "start_indices = []\n",
    "index = 0\n",
    "while index < len(t_cpu):\n",
    "    start_indices.append(index)\n",
    "    start, goal = t_cpu[index, :2], t_cpu[index, 2:4]\n",
    "    index += int(max(np.abs(goal - start)))\n",
    "print (start_indices)\n",
    "print (len(start_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory(start_indices, traj_index):\n",
    "    rstart = start_indices[traj_index]\n",
    "    rend = start_indices[traj_index+1] if traj_index < len(start_indices)-1 else len(t_cpu)\n",
    "    return t_cpu[rstart:rend, :]\n",
    "    \n",
    "def get_trajectories(start_indices):\n",
    "    for i in range(len(start_indices)):\n",
    "        yield i, get_trajectory(start_indices, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained(folder):\n",
    "    chkptFile = 'runs/pretrained/' + folder + '/train_checkpoint.tar'\n",
    "    return torch.load(chkptFile, map_location=device)['model']\n",
    "\n",
    "pretrain_policy = Dense([4, 16, 16, 6], use_last_act=False, prefix='enc').to(device)\n",
    "pretrain_policy.load_state_dict(torch.load('runs/pretrained/04-08-10-24-50-Policy-V2-Dense-CE/autoenc.pth', \n",
    "                                  map_location=device))\n",
    "\n",
    "pretrain_dynamics = Dense([4, 16, 2], prefix='enc').to(device)\n",
    "pretrain_dynamics.load_state_dict(torch.load('runs/pretrained/03-31-18-02-52-Dynamics-V1-Dense-SmoothL1/autoenc.pth', \n",
    "                                    map_location=device))\n",
    "\n",
    "pretrain_imgEncDec = ComposedAutoEncoder(layers_channels=[16,16,16,16], useMaxPool=True, device=device).to(device)\n",
    "pretrain_imgEncDec.load_state_dict(torch.load('runs/pretrained/03-28-14-10-20-DemoPl-V2-ComposedAutoEncoderWithMaxPool-SmoothL1-/autoenc.pth',\n",
    "                               map_location=device))\n",
    "\n",
    "pretrain_envEncDec = load_pretrained('04-20-11-03-59-EnvAutoEnc-V2-DenseAutoEncoder-MSE')\n",
    "pretrain_ImgToEnvBaseLine = load_pretrained('04-21-12-51-48-ImageToEnvFunctionBaseLine-V2-3Conv2Dense-MSE')\n",
    "latentModel0422 = load_pretrained('04-22-23-59-35-TriLossOnCombinedNet-V2-ImageEnvEncoder-MSE_Adam')\n",
    "latentModel0427 = load_pretrained('04-27-21-54-52-QuadLossOnCombinedNet-V2-MultiNet-MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_ImgToEnv_BaseLine = nn.Sequential(OrderedDict([\n",
    "    ('Conv', ImageEncoder(1, [16,16,16], 'imgenc', useMaxPool=True, addFlatten=True)),\n",
    "    ('Dense', Dense([256, 4]))\n",
    "]))\n",
    "adjusted_ImgToEnv_BaseLine.load_state_dict(pretrain_ImgToEnvBaseLine.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latentFilter_gt_x_latent_y(data, latent_output):\n",
    "    return torch.cat((Xt_scaled_adapter(data), latent_output[:, 2:4]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt = torch.load('runs/06-16/06-16-20-33-57-FixImagEncAndPolicyTrainD3EnvDec-V2-LatentPolicyNet-CE/train_checkpoint.tar', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = chkpt['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.latentFilter_gt_x_latent_y(data, latent_output)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.latentFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentPolicyNet(\n",
       "  (latent): Sequential(\n",
       "    (EncNet): ImageEncoderFlatInput(\n",
       "      (net): Sequential(\n",
       "        (imgenc_conv0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (imgenc_relu0): ReLU()\n",
       "        (imgenc_maxpool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (imgenc_conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (imgenc_relu1): ReLU()\n",
       "        (imgenc_maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (imgenc_conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (imgenc_relu2): ReLU()\n",
       "        (imgenc_maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (imgenc_conv3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (imgenc_relu3): ReLU()\n",
       "        (imgenc_maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (imgenc_flat): Flatten()\n",
       "      )\n",
       "      (reshapeInput): Reshape()\n",
       "    )\n",
       "    (DecNet): Dense(\n",
       "      (net): Sequential(\n",
       "        (envdec_fc0): Linear(in_features=64, out_features=16, bias=True)\n",
       "        (envdec_relu0): ReLU()\n",
       "        (envdec_fc1): Linear(in_features=16, out_features=4, bias=True)\n",
       "        (envdec_sig1): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (policy): Dense(\n",
       "    (net): Sequential(\n",
       "      (enc_fc0): Linear(in_features=4, out_features=16, bias=True)\n",
       "      (enc_relu0): ReLU()\n",
       "      (enc_fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (enc_relu1): ReLU()\n",
       "      (enc_fc2): Linear(in_features=16, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_to_disk = True\n",
    "\n",
    "def label_adapter_end_to_end_net(data):\n",
    "    # ut, xt+, It+, yt\n",
    "    return torch.cat((data[:, 1028:1032], data[:, 1034:], data[:, 2:4]), dim=1)\n",
    "\n",
    "def label_adapter_latent_policy_net(data):\n",
    "    # ut, xt+, It+\n",
    "    return torch.cat((data[:, 1028:1032], data[:, 1034:]), dim=1)\n",
    "\n",
    "def run_eval_end_to_end_net(chkpt_file):\n",
    "    log_folder = os.path.dirname(chkpt_file)\n",
    "    chkpt = torch.load(log_folder + '/train_checkpoint.tar', map_location=device)\n",
    "    net = chkpt['model']\n",
    "    label_adapter = label_adapter_latent_policy_net\n",
    "    \n",
    "    errors = torch.zeros((len(start_indices), 6))\n",
    "    allLabels = []\n",
    "    allPredictions = []\n",
    "    for index, trajectory in get_trajectories(start_indices):\n",
    "        labels = label_adapter(trajectory)\n",
    "        with torch.no_grad():\n",
    "            predictions = net.rollout(trajectory)\n",
    "        allLabels.append(labels)\n",
    "        allPredictions.append(predictions)\n",
    "        errors[index][0] = index\n",
    "        errors[index][1] = len(trajectory)\n",
    "        errors[index][2] = eval_policy_accuracy(predictions[:, 0:2], labels[:, 0:2])\n",
    "        errors[index][3] = F.l1_loss(predictions[:, 0:2], labels[:, 0:2])\n",
    "        errors[index][4] = F.l1_loss(predictions[:, 2:4], labels[:, 2:4])\n",
    "        errors[index][5] = F.l1_loss(predictions[-1, 2:4], labels[-1, 2:4])\n",
    "    \n",
    "    aggregate_row_headers = ['Sum', 'Average', 'Min Index', 'Min Value', 'Max Index', 'Max Value', 'Counts']\n",
    "    aggregates = torch.zeros((7, 6))\n",
    "    aggregates[0] = torch.sum(errors, dim=0)\n",
    "    aggregates[1] = aggregates[0] / len(start_indices)\n",
    "    aggregates[3], aggregates[2] = torch.min(errors, dim=0)\n",
    "    aggregates[5], aggregates[4] = torch.max(errors, dim=0)\n",
    "    lower_threshholds = torch.Tensor([-1, 10, 99]) # Total trajectories, trajectories of len > 10, of accuracy > 99\n",
    "    upper_threshholds = torch.Tensor([0.01, 0.01, 0.01]) # trajectories of latent loss, dynamics step loss, goal loss < 0.01\n",
    "    aggregates[6] = torch.sum(torch.cat((\n",
    "        torch.gt(errors[:, :3], lower_threshholds),\n",
    "        torch.lt(errors[:, 3:], upper_threshholds)), dim=1), dim=0)\n",
    "    agg = aggregates.numpy()\n",
    "    \n",
    "    result_folder = log_folder + '/Evaluations'\n",
    "    if persist_to_disk:\n",
    "        os.makedirs(result_folder)\n",
    "\n",
    "        with open(result_folder + '/trajectory_eval_metrics.csv', 'a') as f:\n",
    "            f.write('Trajectory Index,Trajectory Length,Policy Accuracy,Policy L1 Loss,Dynamics Loss (step),Goal Deviation\\n')\n",
    "            f.write('Aggregates:\\n')\n",
    "            for i in range(len(aggregate_row_headers)):\n",
    "                f.write(aggregate_row_headers[i])\n",
    "                f.write(',')\n",
    "                f.write(str.join(',', [str(val) for val in agg[i, 1:]]))\n",
    "                f.write('\\n')\n",
    "            f.write('\\nInidividual:\\n')\n",
    "            np.savetxt(f, errors.numpy(), fmt='%5.2f', delimiter=',')\n",
    "    \n",
    "    sample_descriptions = ['Best Policy Accuracy','Least Policy L1 Error',\n",
    "                           'Least Trajectory Error','Least Goal Error',\n",
    "                           'Worst Policy Accuracy','Highest Policy L1 Error',\n",
    "                           'Highest Trajectory Error','Highest Goal Error']\n",
    "    # For policy, min means worst, for other errors, min means best\n",
    "    indices = torch.cat((aggregates[4, 2:3], aggregates[2, 3:], aggregates[2, 2:3], aggregates[4, 3:])).long()\n",
    "    values = torch.cat((aggregates[5, 2:3], aggregates[3, 3:], aggregates[3, 2:3], aggregates[5, 3:]))\n",
    "    print ('-------------------------------------------------------------')\n",
    "    print (log_folder)\n",
    "    print ('-------------------------------------------------------------')\n",
    "    print ('Number of Trajectories Ended up Within Goal Region: {}'.format(aggregates[6, 5].item()))\n",
    "    print ('Average Policy Accuracy: {}'.format(aggregates[1, 2].item()))\n",
    "    print ('Average Latent Loss: {}'.format(aggregates[1, 3].item()))\n",
    "    print ('Average Trajectory Loss: {}'.format(aggregates[1, 4].item()))\n",
    "    print ('Average Goal Loss: {}'.format(aggregates[1, 5].item()))\n",
    "    print ('')\n",
    "    for i in range(len(sample_descriptions)):\n",
    "        print ('{}: Index = {}, Value = {}'.format(sample_descriptions[i], indices[i], values[i]))\n",
    "        if i == 3:\n",
    "            print ('')\n",
    "\n",
    "    if persist_to_disk:\n",
    "        for i in range(len(sample_descriptions)):\n",
    "            index = indices[i]\n",
    "            labels = allLabels[index]\n",
    "            predictions = allPredictions[index]\n",
    "            filename = '/traj_' + str(index.item()) + '_' + str.join('_', str.split(sample_descriptions[i])) + '.pdf'\n",
    "            with PdfPages(result_folder + filename) as pdf:\n",
    "                for i in range(len(labels)):\n",
    "                    fig = plt.figure()\n",
    "                    plt.subplot(1,2,1)\n",
    "                    plt.imshow(labels[i, 4:].reshape(32,32), cmap=plt.get_cmap(\"gray\"))\n",
    "                    plt.subplot(1,2,2)\n",
    "                    plt.imshow(predictions[i, 4:].reshape(32,32), cmap=plt.get_cmap(\"gray\"))\n",
    "                    pdf.savefig(fig)\n",
    "                    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "runs/06-16/06-16-20-33-57-FixImagEncAndPolicyTrainD3EnvDec-V2-LatentPolicyNet-CE\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region: 89.0\n",
      "Average Policy Accuracy: 62.477874755859375\n",
      "Average Latent Loss: 0.28515496850013733\n",
      "Average Trajectory Loss: 1.2255933284759521\n",
      "Average Goal Loss: 3.693000078201294\n",
      "\n",
      "Best Policy Accuracy: Index = 494, Value = 100.0\n",
      "Least Policy L1 Error: Index = 494, Value = 0.0\n",
      "Least Trajectory Error: Index = 494, Value = 0.0\n",
      "Least Goal Error: Index = 494, Value = 0.0\n",
      "\n",
      "Worst Policy Accuracy: Index = 489, Value = 0.0\n",
      "Highest Policy L1 Error: Index = 153, Value = 1.2999999523162842\n",
      "Highest Trajectory Error: Index = 153, Value = 12.279999732971191\n",
      "Highest Goal Error: Index = 200, Value = 28.0\n",
      "-------------------------------------------------------------\n",
      "runs/06-16/06-16-23-26-42-FixImagEncAndPolicyTrainD3EnvDec-V2-LatentPolicyNet-CE\n",
      "-------------------------------------------------------------\n",
      "Number of Trajectories Ended up Within Goal Region: 304.0\n",
      "Average Policy Accuracy: 88.64527893066406\n",
      "Average Latent Loss: 0.06904911994934082\n",
      "Average Trajectory Loss: 0.2551147937774658\n",
      "Average Goal Loss: 0.9049999713897705\n",
      "\n",
      "Best Policy Accuracy: Index = 496, Value = 100.0\n",
      "Least Policy L1 Error: Index = 496, Value = 0.0\n",
      "Least Trajectory Error: Index = 496, Value = 0.0\n",
      "Least Goal Error: Index = 496, Value = 0.0\n",
      "\n",
      "Worst Policy Accuracy: Index = 260, Value = 0.0\n",
      "Highest Policy L1 Error: Index = 367, Value = 1.2777777910232544\n",
      "Highest Trajectory Error: Index = 21, Value = 9.760869979858398\n",
      "Highest Goal Error: Index = 21, Value = 24.5\n",
      "Time Taken: 62.19239020347595 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for chkpt_file in utils.enumerate_files(rootdir='runs/06-16'):\n",
    "    run_eval_end_to_end_net(chkpt_file)\n",
    "    # shutil.rmtree(os.path.dirname(chkpt_file) + '/Evaluations', ignore_errors=True)\n",
    "    # os.rename(os.path.dirname(chkpt_file) + '/Evaluations', os.path.dirname(chkpt_file) + '/Old_Evaluations')\n",
    "\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = 'runs/05-05/run3/05-05-14-29-58-TrainPolicyOnlyInEndToEnd-V2-EndToEndEnv-CE'\n",
    "chkpt = torch.load(log_folder + '/train_checkpoint.tar', map_location=device)\n",
    "net = chkpt['model']\n",
    "label_adapter = lambda data: torch.cat((data[:, 2:4], data[:, 1028:1032], data[:, 1034:]), dim=1)\n",
    "e = PolicyEvaluator(net, distance_func=F.l1_loss, label_adapter=label_adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = torch.zeros((len(start_indices), 5))\n",
    "allLabels = []\n",
    "allPredictions = []\n",
    "for index, trajectory in get_trajectories(start_indices):\n",
    "    goal_err, step_err, labels, predictions = e.eval_single_trajectory(trajectory)\n",
    "    allLabels.append(labels)\n",
    "    allPredictions.append(predictions)\n",
    "    errors[index][0] = index\n",
    "    errors[index][1] = len(trajectory)\n",
    "    errors[index][2] = F.l1_loss(predictions[:, 0:2], labels[:, 0:2])\n",
    "    errors[index][3] = eval_policy_accuracy(predictions[:, 2:4], labels[:, 2:4])\n",
    "    errors[index][4] = F.l1_loss(predictions[:, 4:6], labels[:, 4:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159, 344, 85, 499]\n",
      "tensor([[1.5900e+02, 1.8000e+01, 2.1521e-02, 1.0000e+02, 0.0000e+00],\n",
      "        [3.4400e+02, 1.0000e+01, 1.3117e+00, 9.0000e+01, 5.0000e-02],\n",
      "        [8.5000e+01, 5.0000e+00, 1.7077e-01, 6.0000e+01, 2.0000e-01],\n",
      "        [4.9900e+02, 1.3000e+01, 8.3551e-02, 1.0000e+02, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "indices = [torch.argmin(errors[:, 2]).item(), torch.argmax(errors[:, 2]).item(),\n",
    "           torch.argmin(errors[:, 3]).item(), torch.argmax(errors[:, 3]).item()]\n",
    "print (indices)\n",
    "print (errors[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "index = 85\n",
    "print (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "traj = get_trajectory(start_indices, index)\n",
    "print (len(traj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8., 24., 13., 26.,  0.,  0.],\n",
      "        [ 9., 24., 13., 26.,  0.,  0.],\n",
      "        [10., 24., 13., 26.,  0.,  0.],\n",
      "        [11., 24., 13., 26.,  0.,  0.],\n",
      "        [12., 25., 13., 26.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "print (traj[:, :6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "tensor(0.6183)\n",
      "tensor(0.9421)\n"
     ]
    }
   ],
   "source": [
    "goal_err, step_err, labels, predictions = e.eval_single_trajectory(traj)\n",
    "print (len(traj))\n",
    "print (goal_err)\n",
    "print (step_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[13.0000, 26.0000, 12.7572, 26.0149],\n",
      "        [13.0000, 26.0000, 13.0115, 26.0237],\n",
      "        [13.0000, 26.0000, 12.9172, 26.1644],\n",
      "        [13.0000, 26.0000, 13.2280, 25.9498],\n",
      "        [13.0000, 26.0000, 13.6645, 25.7751]])\n",
      "tensor([[ 1.,  0.,  9., 24.,  1.,  0.,  9., 24.],\n",
      "        [ 1.,  0., 10., 24.,  1.,  0., 10., 24.],\n",
      "        [ 1.,  0., 11., 24.,  1.,  1., 11., 25.],\n",
      "        [ 1.,  1., 12., 25.,  1.,  1., 12., 26.],\n",
      "        [ 1.,  1., 13., 26.,  1.,  0., 13., 26.]])\n"
     ]
    }
   ],
   "source": [
    "print (torch.cat((labels[:, :2], predictions[:, :2]), dim=1))\n",
    "print (torch.cat((labels[:, 2:6], predictions[:, 2:6]), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [66, 483, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in indices:\n",
    "    print ('-------------------------------------------------------------')\n",
    "    print ('                         {}'.format(index))\n",
    "    print ('-------------------------------------------------------------')\n",
    "#     folder = log_folder + '/Evaluations/{}/'.format(index)\n",
    "#     os.makedirs(folder)\n",
    "    labels = allLabels[index]\n",
    "    predictions = allPredictions[index]\n",
    "    for i in range(len(labels)):    \n",
    "        fig = plt.figure()\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(labels[i, 6:].reshape(32,32), cmap=plt.get_cmap(\"gray\"))\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(predictions[i, 6:].reshape(32,32), cmap=plt.get_cmap(\"gray\"))\n",
    "#         fig.savefig(folder + '/{}.png'.format(i))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Trajectory with highest goal error = {}'.format(torch.argmax(errors[:, 1])))\n",
    "print ('Trajectory with highest average step error = {}'.format(torch.argmax(errors[:, 2])))\n",
    "print ('Trajectory Length, Goal Error, Average Error')\n",
    "for i in range(len(errors)):\n",
    "    print('{},{},{}'.format(*errors[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_no = 386 \n",
    "rstart = start_indices[traj_no]\n",
    "rend = start_indices[traj_no+1] if traj_no < len(start_indices) else len(test_data)\n",
    "trajectory = t_cpu[rstart:rend, :]\n",
    "f = torch.cat((trajectory[:, :4], trajectory[:, 1028:1030]), dim=1)\n",
    "print (len(f))\n",
    "print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_err, step_err, pred_traj, orig_traj, policy_pred, dyn_pred = e.eval_single_trajectory(trajectory)\n",
    "\n",
    "print ('Last step error = {}'.format(goal_err))\n",
    "print ('Average error over all steps = {}'.format(step_err))\n",
    "print ('Original Trajectory and Predicted Trajectory:')\n",
    "print (torch.cat((orig_traj, pred_traj), dim=1))\n",
    "print ('Stepwise deviation from original trajectory:')\n",
    "print (torch.abs(orig_traj-pred_traj))\n",
    "print ('Prediction from Policy:')\n",
    "print (policy_pred - 1.0) # Using minus to bring the policy output to the values we expect\n",
    "print ('Prediction from Dynamics:')\n",
    "print (dyn_pred * 2.0 - 1.0)  # Again bringing the dynamics prediction to the expected range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(**opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demopl",
   "language": "python",
   "name": "demopl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
