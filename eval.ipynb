{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from collections import OrderedDict\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from adapters import *\n",
    "from dataset import NumpyCsvDataSet\n",
    "from runner import ExptRunner\n",
    "from networks.autoencoder import AutoEncoder\n",
    "from networks.composedautoencoder import ComposedAutoEncoder\n",
    "from networks.DenseAutoEncoder import DenseAutoEncoder\n",
    "from networks.ConvVae import ConvVae\n",
    "from networks.vae import VAE\n",
    "from networks.etpr.autoencoder import autoencoder as etprautoenc\n",
    "from networks.dense import Dense\n",
    "from networks.dense import DenseForPolicy\n",
    "from networks.imageencoder import ImageEncoder\n",
    "from networks.multinet import *\n",
    "from networks.lossfunctions import *\n",
    "from helpers import ReportResults\n",
    "from policyeval import PolicyEvaluator\n",
    "from policyeval import eval_policy_accuracy\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=torch.serialization.SourceChangeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = np.get_printoptions()\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "data_folder = 'data/demoplanner/version1'\n",
    "# v1_train_data = NumpyCsvDataSet(data_folder + '/train.csv', device=device)\n",
    "v1_test_data = NumpyCsvDataSet(data_folder + '/test.csv', device=device)\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 12.388941764831543 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "data_folder = 'data/demoplanner/version2'\n",
    "# v2_train_data = NumpyCsvDataSet(data_folder + '/train.csv', device=device)\n",
    "v2_test_data = NumpyCsvDataSet(data_folder + '/test.csv', device=device)\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = v2_test_data.data\n",
    "# train_data = v2_train_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6648, 2058])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# print (train_data.shape)\n",
    "# print (train_data.device)\n",
    "\n",
    "print (test_data.shape)\n",
    "print (test_data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 22, 31, 34, 43, 50, 70, 86, 90, 106, 114, 122, 138, 152, 157, 173, 184, 191, 211, 219, 224, 226, 249, 260, 269, 279, 290, 307, 324, 340, 355, 367, 376, 400, 412, 426, 436, 453, 474, 485, 489, 509, 530, 536, 545, 554, 579, 597, 608, 621, 643, 651, 656, 664, 676, 683, 692, 706, 713, 740, 759, 774, 792, 802, 819, 841, 853, 878, 898, 905, 914, 925, 934, 944, 954, 974, 984, 998, 1007, 1008, 1015, 1025, 1043, 1061, 1065, 1089, 1094, 1103, 1114, 1126, 1129, 1152, 1160, 1177, 1183, 1196, 1207, 1232, 1243, 1265, 1274, 1293, 1302, 1316, 1328, 1350, 1358, 1371, 1375, 1397, 1402, 1422, 1439, 1442, 1454, 1461, 1481, 1500, 1516, 1536, 1550, 1559, 1565, 1577, 1601, 1626, 1645, 1669, 1681, 1694, 1702, 1720, 1729, 1738, 1753, 1777, 1792, 1793, 1794, 1802, 1814, 1818, 1836, 1842, 1865, 1887, 1909, 1915, 1925, 1931, 1941, 1963, 1979, 1998, 2023, 2042, 2068, 2093, 2096, 2106, 2124, 2136, 2149, 2160, 2180, 2194, 2206, 2213, 2236, 2242, 2248, 2260, 2269, 2291, 2304, 2312, 2322, 2336, 2350, 2360, 2380, 2392, 2399, 2412, 2414, 2427, 2440, 2459, 2475, 2489, 2493, 2509, 2523, 2533, 2548, 2561, 2583, 2588, 2604, 2616, 2635, 2660, 2672, 2679, 2687, 2692, 2704, 2718, 2725, 2734, 2758, 2768, 2780, 2795, 2807, 2817, 2821, 2836, 2847, 2860, 2878, 2893, 2915, 2931, 2944, 2948, 2962, 2980, 2989, 3013, 3022, 3025, 3031, 3034, 3047, 3061, 3084, 3095, 3108, 3120, 3126, 3149, 3168, 3176, 3200, 3223, 3231, 3248, 3252, 3267, 3281, 3306, 3329, 3352, 3369, 3384, 3400, 3415, 3438, 3457, 3466, 3471, 3484, 3493, 3500, 3512, 3523, 3526, 3534, 3554, 3555, 3563, 3570, 3577, 3593, 3609, 3619, 3639, 3647, 3657, 3675, 3688, 3706, 3731, 3743, 3764, 3774, 3793, 3810, 3834, 3846, 3862, 3875, 3878, 3883, 3887, 3894, 3897, 3910, 3927, 3944, 3947, 3968, 3993, 4015, 4021, 4031, 4044, 4063, 4072, 4080, 4086, 4104, 4123, 4147, 4166, 4180, 4192, 4216, 4234, 4250, 4266, 4285, 4300, 4319, 4339, 4354, 4355, 4363, 4374, 4396, 4400, 4414, 4421, 4435, 4457, 4482, 4492, 4497, 4501, 4513, 4525, 4540, 4553, 4567, 4577, 4586, 4601, 4608, 4616, 4625, 4635, 4640, 4646, 4667, 4675, 4680, 4695, 4704, 4727, 4742, 4756, 4777, 4793, 4801, 4803, 4816, 4820, 4838, 4849, 4867, 4882, 4902, 4920, 4935, 4948, 4969, 4995, 5004, 5012, 5037, 5059, 5083, 5105, 5125, 5133, 5146, 5171, 5184, 5206, 5215, 5233, 5247, 5253, 5274, 5285, 5302, 5319, 5329, 5347, 5363, 5365, 5382, 5400, 5410, 5432, 5446, 5464, 5472, 5481, 5503, 5508, 5521, 5531, 5553, 5558, 5571, 5583, 5590, 5612, 5621, 5636, 5646, 5650, 5658, 5677, 5692, 5708, 5729, 5739, 5746, 5760, 5768, 5789, 5805, 5828, 5853, 5860, 5875, 5882, 5893, 5919, 5931, 5952, 5958, 5964, 5978, 5989, 6008, 6030, 6050, 6070, 6076, 6079, 6089, 6100, 6114, 6135, 6144, 6153, 6161, 6163, 6187, 6197, 6209, 6219, 6228, 6236, 6253, 6265, 6280, 6288, 6303, 6314, 6327, 6336, 6339, 6342, 6358, 6363, 6371, 6389, 6403, 6415, 6437, 6450, 6462, 6485, 6504, 6519, 6520, 6534, 6551, 6564, 6580, 6586, 6596, 6602, 6624, 6635]\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "t_cpu = test_data.data.cpu()\n",
    "start_indices = []\n",
    "index = 0\n",
    "while index < len(t_cpu):\n",
    "    start_indices.append(index)\n",
    "    start, goal = t_cpu[index, :2], t_cpu[index, 2:4]\n",
    "    index += int(max(np.abs(goal - start)))\n",
    "print (start_indices)\n",
    "print (len(start_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory(start_indices, traj_index):\n",
    "    rstart = start_indices[traj_index]\n",
    "    rend = start_indices[traj_index+1] if traj_index < len(start_indices)-1 else len(t_cpu)\n",
    "    return t_cpu[rstart:rend, :]\n",
    "    \n",
    "def get_trajectories(start_indices):\n",
    "    for i in range(len(start_indices)):\n",
    "        yield i, get_trajectory(start_indices, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_policy = Dense([4, 16, 16, 6], use_last_act=False, prefix='enc')\n",
    "pretrain_policy.load_state_dict(torch.load('runs/pretrained/04-08-10-24-50-Policy-V2-Dense-CE/autoenc.pth', \n",
    "                                  map_location=device))\n",
    "\n",
    "pretrain_dynamics = Dense([4, 16, 2], prefix='enc')\n",
    "pretrain_dynamics.load_state_dict(torch.load('runs/pretrained/03-31-18-02-52-Dynamics-V1-Dense-SmoothL1/autoenc.pth', \n",
    "                                    map_location=device))\n",
    "\n",
    "pretrain_imgEncDec = ComposedAutoEncoder(layers_channels=[16,16,16,16], useMaxPool=True, device=device).to(device)\n",
    "pretrain_imgEncDec.load_state_dict(torch.load('runs/pretrained/03-28-14-10-20-DemoPl-V2-ComposedAutoEncoderWithMaxPool-SmoothL1-/autoenc.pth',\n",
    "                               map_location=device))\n",
    "\n",
    "pretrain_envEncDec_chkpt = torch.load(\n",
    "    'runs/pretrained/04-20-11-03-59-EnvAutoEnc-V2-DenseAutoEncoder-MSE/train_checkpoint.tar',map_location=device)\n",
    "pretrain_envEncDec = pretrain_envEncDec_chkpt['model']\n",
    "\n",
    "pretrain_ImgToEnvBaseLine_chkpt = torch.load(\n",
    "    'runs/pretrained/04-21-12-51-48-ImageToEnvFunctionBaseLine-V2-3Conv2Dense-MSE/train_checkpoint.tar',map_location=device)\n",
    "pretrain_ImgToEnvBaseLine = pretrain_ImgToEnvBaseLine_chkpt['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_ImgToEnv_BaseLine = nn.Sequential(OrderedDict([\n",
    "    ('Conv', ImageEncoder(1, [16,16,16], 'imgenc', useMaxPool=True, addFlatten=True)),\n",
    "    ('Dense', Dense([256, 4]))\n",
    "]))\n",
    "adjusted_ImgToEnv_BaseLine.load_state_dict(pretrain_ImgToEnvBaseLine.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_to_disk = True\n",
    "\n",
    "def run_eval_end_to_end_net(chkpt_file):\n",
    "    log_folder = os.path.dirname(chkpt_file)\n",
    "    chkpt = torch.load(log_folder + '/train_checkpoint.tar', map_location=device)\n",
    "    net = chkpt['model']\n",
    "    label_adapter = lambda data: torch.cat((data[:, 2:4], data[:, 1028:1032], data[:, 1034:]), dim=1)\n",
    "    \n",
    "    errors = torch.zeros((len(start_indices), 6))\n",
    "    allLabels = []\n",
    "    allPredictions = []\n",
    "    for index, trajectory in get_trajectories(start_indices):\n",
    "        labels = label_adapter(trajectory)\n",
    "        with torch.no_grad():\n",
    "            predictions = net.rollout(trajectory)\n",
    "        allLabels.append(labels)\n",
    "        allPredictions.append(predictions)\n",
    "        errors[index][0] = index\n",
    "        errors[index][1] = len(trajectory)\n",
    "        errors[index][2] = eval_policy_accuracy(predictions[:, 2:4], labels[:, 2:4])\n",
    "        errors[index][3] = F.l1_loss(predictions[:, 0:2], labels[:, 0:2])\n",
    "        errors[index][4] = F.l1_loss(predictions[:, 4:6], labels[:, 4:6])\n",
    "        errors[index][5] = F.l1_loss(predictions[-1, 4:6], labels[-1, 4:6])\n",
    "    \n",
    "    aggregate_row_headers = ['Sum', 'Average', 'Min Index', 'Min Value', 'Max Index', 'Max Value']\n",
    "    aggregates = torch.zeros((6, 6))\n",
    "    aggregates[0] = torch.sum(errors, dim=0)\n",
    "    aggregates[1] = aggregates[0] / len(start_indices)\n",
    "    aggregates[3], aggregates[2] = torch.min(errors, dim=0)\n",
    "    aggregates[5], aggregates[4] = torch.max(errors, dim=0)\n",
    "    agg = aggregates.numpy()\n",
    "    \n",
    "    result_folder = log_folder + '/Evaluations'\n",
    "    if persist_to_disk:\n",
    "        os.makedirs(result_folder)\n",
    "\n",
    "        with open(result_folder + '/trajectory_eval_metrics.csv', 'a') as f:\n",
    "            f.write('Trajectory Index,Trajectory Length,Policy Accuracy,Latent L1 Loss,Dynamics Loss (step),Goal Deviation\\n')\n",
    "            f.write('Aggregates:\\n')\n",
    "            for i in range(len(aggregate_row_headers)):\n",
    "                f.write(aggregate_row_headers[i])\n",
    "                f.write(',')\n",
    "                f.write(str.join(',', [str(val) for val in agg[i, 1:]]))\n",
    "                f.write('\\n')\n",
    "            f.write('\\nInidividual:\\n')\n",
    "            np.savetxt(f, errors.numpy(), fmt='%5.2f', delimiter=',')\n",
    "    \n",
    "    sample_descriptions = ['Best Policy Accuracy','Least Latent Error',\n",
    "                           'Least Trajectory Error','Least Goal Error',\n",
    "                           'Worst Policy Accuracy','Highest Latent Error',\n",
    "                           'Highest Trajectory Error','Highest Goal Error',]\n",
    "    # For policy, min means worst, for other errors, min means best\n",
    "    indices = torch.cat((aggregates[4, 2:3], aggregates[2, 3:], aggregates[2, 2:3], aggregates[4, 3:])).long()\n",
    "    values = torch.cat((aggregates[5, 2:3], aggregates[3, 3:], aggregates[3, 2:3], aggregates[5, 3:]))\n",
    "    print ('-------------------------------------------------------------')\n",
    "    print (log_folder)\n",
    "    print ('-------------------------------------------------------------')\n",
    "    print ('Average Policy Accuracy: {}'.format(aggregates[1, 2].item()))\n",
    "    print ('Average Latent Loss: {}'.format(aggregates[1, 3].item()))\n",
    "    print ('Average Trajectory Loss: {}'.format(aggregates[1, 4].item()))\n",
    "    print ('Average Goal Loss: {}'.format(aggregates[1, 5].item()))\n",
    "    print ('')\n",
    "    for i in range(len(sample_descriptions)):\n",
    "        print ('{}: Index = {}, Value = {}'.format(sample_descriptions[i], indices[i], values[i]))\n",
    "        if i == 3:\n",
    "            print ('')\n",
    "\n",
    "    if persist_to_disk:\n",
    "        for i in range(len(sample_descriptions)):\n",
    "            index = indices[i]\n",
    "            labels = allLabels[index]\n",
    "            predictions = allPredictions[index]\n",
    "            filename = '/traj_' + str(index.item()) + '_' + str.join('_', str.split(sample_descriptions[i])) + '.pdf'\n",
    "            with PdfPages(result_folder + filename) as pdf:\n",
    "                for i in range(len(labels)):\n",
    "                    fig = plt.figure()\n",
    "                    plt.subplot(1,2,1)\n",
    "                    plt.imshow(labels[i, 6:].reshape(32,32), cmap=plt.get_cmap(\"gray\"))\n",
    "                    plt.subplot(1,2,2)\n",
    "                    plt.imshow(predictions[i, 6:].reshape(32,32), cmap=plt.get_cmap(\"gray\"))\n",
    "                    pdf.savefig(fig)\n",
    "                    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "runs/05-05/run1/05-05-10-05-17-FineTunePreTrainedEndToEnd-V2-EndToEndEnv-MSE\n",
      "-------------------------------------------------------------\n",
      "Average Policy Accuracy: 13.17237377166748\n",
      "Average Latent Loss: 11.240391731262207\n",
      "Average Trajectory Loss: 5.948480606079102\n",
      "Average Goal Loss: 11.817000389099121\n",
      "\n",
      "Best Policy Accuracy: Index = 460, Value = 100.0\n",
      "Least Latent Error: Index = 249, Value = 1.649496078491211\n",
      "Least Trajectory Error: Index = 460, Value = 0.0\n",
      "Least Goal Error: Index = 460, Value = 0.0\n",
      "\n",
      "Worst Policy Accuracy: Index = 498, Value = 0.0\n",
      "Highest Latent Error: Index = 382, Value = 27.10991859436035\n",
      "Highest Trajectory Error: Index = 418, Value = 20.159090042114258\n",
      "Highest Goal Error: Index = 418, Value = 41.0\n",
      "-------------------------------------------------------------\n",
      "runs/05-05/run1/05-05-10-07-01-FineTunePreTrainedEndToEnd-V2-EndToEndEnv-L1\n",
      "-------------------------------------------------------------\n",
      "Average Policy Accuracy: 7.153665065765381\n",
      "Average Latent Loss: 9.035820960998535\n",
      "Average Trajectory Loss: 6.51381254196167\n",
      "Average Goal Loss: 13.220999717712402\n",
      "\n",
      "Best Policy Accuracy: Index = 269, Value = 100.0\n",
      "Least Latent Error: Index = 494, Value = 0.9641683101654053\n",
      "Least Trajectory Error: Index = 269, Value = 0.0\n",
      "Least Goal Error: Index = 269, Value = 0.0\n",
      "\n",
      "Worst Policy Accuracy: Index = 499, Value = 0.0\n",
      "Highest Latent Error: Index = 386, Value = 20.350000381469727\n",
      "Highest Trajectory Error: Index = 153, Value = 16.15999984741211\n",
      "Highest Goal Error: Index = 153, Value = 37.0\n",
      "-------------------------------------------------------------\n",
      "runs/05-05/run2/05-05-13-42-14-FineTunePreTrainedEndToEnd-V2-EndToEndEnv-MSE\n",
      "-------------------------------------------------------------\n",
      "Average Policy Accuracy: 4.573910713195801\n",
      "Average Latent Loss: 10.621247291564941\n",
      "Average Trajectory Loss: 7.317640781402588\n",
      "Average Goal Loss: 14.621999740600586\n",
      "\n",
      "Best Policy Accuracy: Index = 489, Value = 100.0\n",
      "Least Latent Error: Index = 269, Value = 0.9206522703170776\n",
      "Least Trajectory Error: Index = 489, Value = 0.0\n",
      "Least Goal Error: Index = 489, Value = 0.0\n",
      "\n",
      "Worst Policy Accuracy: Index = 499, Value = 0.0\n",
      "Highest Latent Error: Index = 58, Value = 23.843406677246094\n",
      "Highest Trajectory Error: Index = 58, Value = 17.740739822387695\n",
      "Highest Goal Error: Index = 58, Value = 36.5\n",
      "-------------------------------------------------------------\n",
      "runs/05-05/run2/05-05-13-44-15-FineTunePreTrainedEndToEnd-V2-EndToEndEnv-L1\n",
      "-------------------------------------------------------------\n",
      "Average Policy Accuracy: 6.276965141296387\n",
      "Average Latent Loss: 9.249621391296387\n",
      "Average Trajectory Loss: 6.678257942199707\n",
      "Average Goal Loss: 13.46399974822998\n",
      "\n",
      "Best Policy Accuracy: Index = 462, Value = 70.0\n",
      "Least Latent Error: Index = 475, Value = 0.7661561965942383\n",
      "Least Trajectory Error: Index = 296, Value = 0.1666666716337204\n",
      "Least Goal Error: Index = 296, Value = 0.5\n",
      "\n",
      "Worst Policy Accuracy: Index = 498, Value = 0.0\n",
      "Highest Latent Error: Index = 58, Value = 23.69956398010254\n",
      "Highest Trajectory Error: Index = 58, Value = 18.259260177612305\n",
      "Highest Goal Error: Index = 58, Value = 37.5\n",
      "-------------------------------------------------------------\n",
      "runs/05-05/run3/05-05-14-29-58-TrainPolicyOnlyInEndToEnd-V2-EndToEndEnv-CE\n",
      "-------------------------------------------------------------\n",
      "Average Policy Accuracy: 99.38069152832031\n",
      "Average Latent Loss: 0.08765333145856857\n",
      "Average Trajectory Loss: 0.004609264899045229\n",
      "Average Goal Loss: 0.02500000037252903\n",
      "\n",
      "Best Policy Accuracy: Index = 499, Value = 100.0\n",
      "Least Latent Error: Index = 159, Value = 0.021521197631955147\n",
      "Least Trajectory Error: Index = 499, Value = 0.0\n",
      "Least Goal Error: Index = 499, Value = 0.0\n",
      "\n",
      "Worst Policy Accuracy: Index = 85, Value = 60.0\n",
      "Highest Latent Error: Index = 344, Value = 1.3116885423660278\n",
      "Highest Trajectory Error: Index = 239, Value = 0.25\n",
      "Highest Goal Error: Index = 369, Value = 1.0\n",
      "-------------------------------------------------------------\n",
      "runs/05-05/run4/05-05-16-53-05-InitAllTrainPolAndDynamicsInEndToEnd-V2-EndToEndEnv-MSE\n",
      "-------------------------------------------------------------\n",
      "Average Policy Accuracy: 11.678277015686035\n",
      "Average Latent Loss: 0.07862233370542526\n",
      "Average Trajectory Loss: 7.208633899688721\n",
      "Average Goal Loss: 13.378999710083008\n",
      "\n",
      "Best Policy Accuracy: Index = 488, Value = 100.0\n",
      "Least Latent Error: Index = 336, Value = 0.010334014892578125\n",
      "Least Trajectory Error: Index = 488, Value = 0.0\n",
      "Least Goal Error: Index = 488, Value = 0.0\n",
      "\n",
      "Worst Policy Accuracy: Index = 498, Value = 0.0\n",
      "Highest Latent Error: Index = 189, Value = 0.7055575251579285\n",
      "Highest Trajectory Error: Index = 200, Value = 24.559999465942383\n",
      "Highest Goal Error: Index = 200, Value = 48.5\n",
      "-------------------------------------------------------------\n",
      "runs/05-05/run4/05-05-17-10-46-InitAllTrainPolAndDynamicsInEndToEnd-V2-EndToEndEnv-L1\n",
      "-------------------------------------------------------------\n",
      "Average Policy Accuracy: 11.678277015686035\n",
      "Average Latent Loss: 0.07862233370542526\n",
      "Average Trajectory Loss: 7.208633899688721\n",
      "Average Goal Loss: 13.378999710083008\n",
      "\n",
      "Best Policy Accuracy: Index = 488, Value = 100.0\n",
      "Least Latent Error: Index = 336, Value = 0.010334014892578125\n",
      "Least Trajectory Error: Index = 488, Value = 0.0\n",
      "Least Goal Error: Index = 488, Value = 0.0\n",
      "\n",
      "Worst Policy Accuracy: Index = 498, Value = 0.0\n",
      "Highest Latent Error: Index = 189, Value = 0.7055575251579285\n",
      "Highest Trajectory Error: Index = 200, Value = 24.559999465942383\n",
      "Highest Goal Error: Index = 200, Value = 48.5\n",
      "-------------------------------------------------------------\n",
      "runs/05-05/run4/05-05-17-28-28-InitImageEnvTrainPolAndDynamicsInEndToEnd-V2-EndToEndEnv-MSE\n",
      "-------------------------------------------------------------\n",
      "Average Policy Accuracy: 11.678277015686035\n",
      "Average Latent Loss: 0.07862233370542526\n",
      "Average Trajectory Loss: 7.208633899688721\n",
      "Average Goal Loss: 13.378999710083008\n",
      "\n",
      "Best Policy Accuracy: Index = 488, Value = 100.0\n",
      "Least Latent Error: Index = 336, Value = 0.010334014892578125\n",
      "Least Trajectory Error: Index = 488, Value = 0.0\n",
      "Least Goal Error: Index = 488, Value = 0.0\n",
      "\n",
      "Worst Policy Accuracy: Index = 498, Value = 0.0\n",
      "Highest Latent Error: Index = 189, Value = 0.7055575251579285\n",
      "Highest Trajectory Error: Index = 200, Value = 24.559999465942383\n",
      "Highest Goal Error: Index = 200, Value = 48.5\n",
      "-------------------------------------------------------------\n",
      "runs/05-05/run4/05-05-17-46-06-InitImageEnvTrainPolAndDynamicsInEndToEnd-V2-EndToEndEnv-L1\n",
      "-------------------------------------------------------------\n",
      "Average Policy Accuracy: 4.415327548980713\n",
      "Average Latent Loss: 0.0690721720457077\n",
      "Average Trajectory Loss: 8.143991470336914\n",
      "Average Goal Loss: 14.782999992370605\n",
      "\n",
      "Best Policy Accuracy: Index = 326, Value = 100.0\n",
      "Least Latent Error: Index = 336, Value = 0.009683609008789062\n",
      "Least Trajectory Error: Index = 326, Value = 0.0\n",
      "Least Goal Error: Index = 326, Value = 0.0\n",
      "\n",
      "Worst Policy Accuracy: Index = 499, Value = 0.0\n",
      "Highest Latent Error: Index = 7, Value = 0.4960709810256958\n",
      "Highest Trajectory Error: Index = 386, Value = 23.899999618530273\n",
      "Highest Goal Error: Index = 386, Value = 42.0\n",
      "Time Taken: 356.7443082332611 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for chkpt_file in utils.enumerate_files(rootdir='runs/05-05'):\n",
    "    run_eval_end_to_end_net(chkpt_file)\n",
    "    # shutil.rmtree(os.path.dirname(chkpt_file) + '/Evaluations', ignore_errors=True)\n",
    "    # os.rename(os.path.dirname(chkpt_file) + '/Evaluations', os.path.dirname(chkpt_file) + '/Old_Evaluations')\n",
    "\n",
    "print (\"Time Taken: {} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = 'runs/05-05/run3/05-05-14-29-58-TrainPolicyOnlyInEndToEnd-V2-EndToEndEnv-CE'\n",
    "chkpt = torch.load(log_folder + '/train_checkpoint.tar', map_location=device)\n",
    "net = chkpt['model']\n",
    "label_adapter = lambda data: torch.cat((data[:, 2:4], data[:, 1028:1032], data[:, 1034:]), dim=1)\n",
    "e = PolicyEvaluator(net, distance_func=F.l1_loss, label_adapter=label_adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = torch.zeros((len(start_indices), 5))\n",
    "allLabels = []\n",
    "allPredictions = []\n",
    "for index, trajectory in get_trajectories(start_indices):\n",
    "    goal_err, step_err, labels, predictions = e.eval_single_trajectory(trajectory)\n",
    "    allLabels.append(labels)\n",
    "    allPredictions.append(predictions)\n",
    "    errors[index][0] = index\n",
    "    errors[index][1] = len(trajectory)\n",
    "    errors[index][2] = F.l1_loss(predictions[:, 0:2], labels[:, 0:2])\n",
    "    errors[index][3] = eval_policy_accuracy(predictions[:, 2:4], labels[:, 2:4])\n",
    "    errors[index][4] = F.l1_loss(predictions[:, 4:6], labels[:, 4:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159, 344, 85, 499]\n",
      "tensor([[1.5900e+02, 1.8000e+01, 2.1521e-02, 1.0000e+02, 0.0000e+00],\n",
      "        [3.4400e+02, 1.0000e+01, 1.3117e+00, 9.0000e+01, 5.0000e-02],\n",
      "        [8.5000e+01, 5.0000e+00, 1.7077e-01, 6.0000e+01, 2.0000e-01],\n",
      "        [4.9900e+02, 1.3000e+01, 8.3551e-02, 1.0000e+02, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "indices = [torch.argmin(errors[:, 2]).item(), torch.argmax(errors[:, 2]).item(),\n",
    "           torch.argmin(errors[:, 3]).item(), torch.argmax(errors[:, 3]).item()]\n",
    "print (indices)\n",
    "print (errors[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "index = 85\n",
    "print (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "traj = get_trajectory(start_indices, index)\n",
    "print (len(traj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8., 24., 13., 26.,  0.,  0.],\n",
      "        [ 9., 24., 13., 26.,  0.,  0.],\n",
      "        [10., 24., 13., 26.,  0.,  0.],\n",
      "        [11., 24., 13., 26.,  0.,  0.],\n",
      "        [12., 25., 13., 26.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "print (traj[:, :6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "tensor(0.6183)\n",
      "tensor(0.9421)\n"
     ]
    }
   ],
   "source": [
    "goal_err, step_err, labels, predictions = e.eval_single_trajectory(traj)\n",
    "print (len(traj))\n",
    "print (goal_err)\n",
    "print (step_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[13.0000, 26.0000, 12.7572, 26.0149],\n",
      "        [13.0000, 26.0000, 13.0115, 26.0237],\n",
      "        [13.0000, 26.0000, 12.9172, 26.1644],\n",
      "        [13.0000, 26.0000, 13.2280, 25.9498],\n",
      "        [13.0000, 26.0000, 13.6645, 25.7751]])\n",
      "tensor([[ 1.,  0.,  9., 24.,  1.,  0.,  9., 24.],\n",
      "        [ 1.,  0., 10., 24.,  1.,  0., 10., 24.],\n",
      "        [ 1.,  0., 11., 24.,  1.,  1., 11., 25.],\n",
      "        [ 1.,  1., 12., 25.,  1.,  1., 12., 26.],\n",
      "        [ 1.,  1., 13., 26.,  1.,  0., 13., 26.]])\n"
     ]
    }
   ],
   "source": [
    "print (torch.cat((labels[:, :2], predictions[:, :2]), dim=1))\n",
    "print (torch.cat((labels[:, 2:6], predictions[:, 2:6]), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [66, 483, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in indices:\n",
    "    print ('-------------------------------------------------------------')\n",
    "    print ('                         {}'.format(index))\n",
    "    print ('-------------------------------------------------------------')\n",
    "#     folder = log_folder + '/Evaluations/{}/'.format(index)\n",
    "#     os.makedirs(folder)\n",
    "    labels = allLabels[index]\n",
    "    predictions = allPredictions[index]\n",
    "    for i in range(len(labels)):    \n",
    "        fig = plt.figure()\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(labels[i, 6:].reshape(32,32), cmap=plt.get_cmap(\"gray\"))\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(predictions[i, 6:].reshape(32,32), cmap=plt.get_cmap(\"gray\"))\n",
    "#         fig.savefig(folder + '/{}.png'.format(i))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Trajectory with highest goal error = {}'.format(torch.argmax(errors[:, 1])))\n",
    "print ('Trajectory with highest average step error = {}'.format(torch.argmax(errors[:, 2])))\n",
    "print ('Trajectory Length, Goal Error, Average Error')\n",
    "for i in range(len(errors)):\n",
    "    print('{},{},{}'.format(*errors[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_no = 386 \n",
    "rstart = start_indices[traj_no]\n",
    "rend = start_indices[traj_no+1] if traj_no < len(start_indices) else len(test_data)\n",
    "trajectory = t_cpu[rstart:rend, :]\n",
    "f = torch.cat((trajectory[:, :4], trajectory[:, 1028:1030]), dim=1)\n",
    "print (len(f))\n",
    "print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_err, step_err, pred_traj, orig_traj, policy_pred, dyn_pred = e.eval_single_trajectory(trajectory)\n",
    "\n",
    "print ('Last step error = {}'.format(goal_err))\n",
    "print ('Average error over all steps = {}'.format(step_err))\n",
    "print ('Original Trajectory and Predicted Trajectory:')\n",
    "print (torch.cat((orig_traj, pred_traj), dim=1))\n",
    "print ('Stepwise deviation from original trajectory:')\n",
    "print (torch.abs(orig_traj-pred_traj))\n",
    "print ('Prediction from Policy:')\n",
    "print (policy_pred - 1.0) # Using minus to bring the policy output to the values we expect\n",
    "print ('Prediction from Dynamics:')\n",
    "print (dyn_pred * 2.0 - 1.0)  # Again bringing the dynamics prediction to the expected range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(**opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demopl",
   "language": "python",
   "name": "demopl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
